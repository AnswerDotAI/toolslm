[
  {
    "objectID": "funccall.html",
    "href": "funccall.html",
    "title": "funccall source",
    "section": "",
    "text": "Exported source\nimport asyncio, inspect, json, ast\nfrom collections import abc\nfrom fastcore.utils import *\nfrom fastcore.docments import docments\nfrom typing import get_origin, get_args, Dict, List, Optional, Tuple, Union, Any\nfrom types import UnionType\nfrom typing import get_type_hints\nfrom inspect import Parameter, Signature\nfrom decimal import Decimal\nfrom uuid import UUID\nfrom functools import reduce",
    "crumbs": [
      "funccall source"
    ]
  },
  {
    "objectID": "funccall.html#function-calling",
    "href": "funccall.html#function-calling",
    "title": "funccall source",
    "section": "Function calling",
    "text": "Function calling\n\nFunction to schema\nMany LLMs do function calling (aka tool use) by taking advantage of JSON schema.\nWe’ll use docments to make getting JSON schema from Python functions as ergonomic as possible. Each parameter (and the return value) should have a type, and a docments comment with the description of what it is. Here’s an example:\n\ndef silly_sum(\n    a:int, # First thing to sum\n    b:int=1, # Second thing to sum\n    c:list[int]=None, # A pointless argument\n) -&gt; int: # The sum of the inputs\n    \"Adds a + b.\"\n    return a + b\n\nThis is what docments makes of that:\n\nd = docments(silly_sum, full=True)\nd\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'First thing to sum'},\n  'b': {'anno': &lt;class 'int'&gt;, 'default': 1, 'docment': 'Second thing to sum'},\n  'c': {'anno': list[int], 'default': None, 'docment': 'A pointless argument'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'The sum of the inputs'}}\n\n\nNote that this is an AttrDict so we can treat it like an object, or a dict:\n\nd.a.docment, d['a']['anno']\n\n('First thing to sum', int)\n\n\n\n\nExported source\ndef _types(t:type)-&gt;tuple[str,Optional[str]]:\n    \"Tuple of json schema type name and (if appropriate) array item name.\"\n    if t is empty: raise TypeError('Missing type')\n    tmap = {int:\"integer\", float:\"number\", str:\"string\", bool:\"boolean\", list:\"array\", dict:\"object\"}\n    tmap.update({k.__name__: v for k, v in tmap.items()})\n    if getattr(t, '__origin__', None) in (list,tuple,set):\n        args = getattr(t, '__args__', None)\n        item_type = \"object\" if not args else tmap.get(t.__args__[0].__name__, \"object\")\n        return \"array\", item_type\n    # if t is a string like 'int', directly use the string as the key\n    elif isinstance(t, str): return tmap.get(t, \"object\"), None\n    # if t is the type itself and a container\n    elif get_origin(t): return tmap.get(get_origin(t).__name__, \"object\"), None\n    # if t is the type itself like int, use the __name__ representation as the key\n    else: return tmap.get(t.__name__, \"object\"), None\n\n\nThis internal function is needed to convert Python types into JSON schema types.\n\n_types(list[int]), _types(set[int]), _types(int), _types('int')\n\n(('array', 'integer'),\n ('array', 'integer'),\n ('integer', None),\n ('integer', None))\n\n\n\n_types(List[int]), _types(Optional[str]), _types(str | None), _types(Tuple[str, int])\n\n(('array', 'integer'), ('object', None), ('object', None), ('array', 'string'))\n\n\nNote the current behavior:\n\nignores all but the first argument for tuples\nunion types map to object which is a stand-in for arbitrary types\n\nThese and other approximations may require further refinement in the future.\nWill also convert custom types to the object type.\n\nclass Custom: a: int\n_types(list[Custom]), _types(Custom)\n\n(('array', 'object'), ('object', None))\n\n\n\n\nExported source\ndef _param(\n    name, # param name\n    info, # dict from docments\n    evalable=False): # stringify defaults that can't be literal_eval'd?\n    \"json schema parameter given `name` and `info` from docments full dict\"\n    paramt,itemt = _types(info.anno)\n    pschema = dict(type=paramt, description=info.docment or \"\")\n    if itemt: pschema[\"items\"] = {\"type\": itemt}\n    if info.default is not empty:\n        if evalable:\n            try: ast.literal_eval(repr(info.default))\n            except: pschema[\"default\"] = str(info.default)\n            else: pschema[\"default\"] = info.default\n        else: pschema[\"default\"] = info.default\n    return pschema\n\n\nThis private function converts a key/value pair from the docments structure into the dict that will be needed for the schema.\n\nn,o = first(d.items())\nprint(n,'//', o)\n_param(n, o)\n\na // {'docment': 'First thing to sum', 'anno': &lt;class 'int'&gt;, 'default': &lt;class 'inspect._empty'&gt;}\n\n\n{'type': 'integer', 'description': 'First thing to sum'}\n\n\n\nn,o\n\n('a',\n {'docment': 'First thing to sum', 'anno': int, 'default': inspect._empty})\n\n\n\nd\n\n{ 'a': { 'anno': &lt;class 'int'&gt;,\n         'default': &lt;class 'inspect._empty'&gt;,\n         'docment': 'First thing to sum'},\n  'b': {'anno': &lt;class 'int'&gt;, 'default': 1, 'docment': 'Second thing to sum'},\n  'c': {'anno': list[int], 'default': None, 'docment': 'A pointless argument'},\n  'return': { 'anno': &lt;class 'int'&gt;,\n              'default': &lt;class 'inspect._empty'&gt;,\n              'docment': 'The sum of the inputs'}}\n\n\n\n_handle_type(int, None), _handle_type(Path, None)\n\n({'type': 'integer'}, {'type': 'string', 'format': 'Path'})\n\n\n\n# gemini expect `items` to be defined for arrays\n_handle_type(list, None), _handle_type(tuple[str], None), _handle_type(set[str], None)\n\n({'type': 'array', 'items': {}},\n {'type': 'array', 'items': {}},\n {'type': 'array', 'items': {}})\n\n\n\n_handle_type(dict, None), _handle_type(dict[str,str], None)\n\n({'type': 'object'}, {'type': 'object'})\n\n\n\nassert _is_parameterized(list[int]) == True\nassert _is_parameterized(int) == False\nassert _is_container(list[int]) == True\nassert _is_container(dict[str, int]) == True\nassert _is_container(int) == False\n\nFor union and optional types, Union covers older Union[str] syntax while UnionType covers 3.10+ str | None syntax.\n\ndef _example_new_unioin(opt_tup: str | None):\n    pass\n\nd = docments(_example_new_unioin, full=True)\nanno1 = first(d.items())[1].anno\n(anno1, get_origin(anno1), get_args(anno1))\n\n(str | None, types.UnionType, (str, NoneType))\n\n\n\ndef _example_old_union(opt_tup: Union[str, type(None)] =None):\n    pass\n\nd = docments(_example_old_union, full=True)\nanno2 = first(d.items())[1].anno\n(anno2, get_origin(anno2), get_args(anno2))\n\n(typing.Optional[str], typing.Union, (str, NoneType))\n\n\nSupport for both union types is part of the broader container handling:\n\n# Test primitive types\ndefs = {}\nassert _handle_type(int, defs) == {'type': 'integer'}\nassert _handle_type(str, defs) == {'type': 'string'}\nassert _handle_type(bool, defs) == {'type': 'boolean'}\nassert _handle_type(float, defs) == {'type': 'number'}\n\n# Test custom class\nclass TestClass:\n    def __init__(self, x: int, y: int): store_attr()\n\nresult = _handle_type(TestClass, defs)\nassert result == {'$ref': '#/$defs/TestClass'}\nassert 'TestClass' in defs\nassert defs['TestClass']['type'] == 'object'\nassert 'properties' in defs['TestClass']\n\n\n# Test primitive types in containers\nassert _handle_container(list, (int,), defs) == {'type': 'array', 'items': {'type': 'integer'}}\nassert _handle_container(tuple, (str,), defs) == {'type': 'array', 'items': {'type': 'string'}}\nassert _handle_container(set, (str,), defs) == {'type': 'array', 'items': {'type': 'string'}, 'uniqueItems': True}\nassert _handle_container(dict, (str,bool), defs) == {'type': 'object', 'additionalProperties': {'type': 'boolean'}}\n\nresult = _handle_container(list, (TestClass,), defs)\nassert result == {'type': 'array', 'items': {'$ref': '#/$defs/TestClass'}}\nassert 'TestClass' in defs\n\n# Test complex nested structure\nComplexType = dict[str, list[TestClass]]\nresult = _handle_container(dict, (str, list[TestClass]), defs)\nassert result == {\n    'type': 'object',\n    'additionalProperties': {\n        'type': 'array',\n        'items': {'$ref': '#/$defs/TestClass'}\n    }\n}\n\n\n# Test processing of a required integer property\nprops, req = {}, {}\nclass TestClass:\n    \"Test class\"\n    def __init__(\n        self,\n        x: int, # First thing\n        y: list[float], # Second thing\n        z: str = \"default\", # Third thing\n    ): store_attr()\n\nd = docments(TestClass, full=True)\n_process_property('x', d.x, props, req, defs)\nassert 'x' in props\nassert props['x']['type'] == 'integer'\nassert 'x' in req\n\n# Test processing of a required list property\n_process_property('y', d.y, props, req, defs)\nassert 'y' in props\nassert props['y']['type'] == 'array'\nassert props['y']['items']['type'] == 'number'\nassert 'y' in req\n\n# Test processing of an optional string property with default\n_process_property('z', d.z, props, req, defs)\nassert 'z' in props\nassert props['z']['type'] == 'string'\nassert props['z']['default'] == \"default\"\nassert 'z' not in req\n\n\nsource\n\n\nget_schema\n\ndef get_schema(\n    f:Union, # Function to get schema for\n    pname:str='input_schema', # Key name for parameters\n    evalable:bool=False, # stringify defaults that can't be literal_eval'd?\n    skip_hidden:bool=False, # skip parameters starting with '_'?\n    name:NoneType=None, # Override function name (useful for dotted paths like 'obj.method')\n)-&gt;dict: # {'name':..., 'description':..., pname:...}\n\nGenerate JSON schema for a class, function, or method\n\nget_schema(get_schema)\n\n{'name': 'get_schema',\n 'description': \"Generate JSON schema for a class, function, or method\\n\\nReturns:\\n- {'name':..., 'description':..., pname:...} (type: object)\",\n 'input_schema': {'type': 'object',\n  'properties': {'f': {'type': 'object',\n    'description': 'Function to get schema for',\n    'anyOf': [{'type': 'object'}, {'type': 'object'}]},\n   'pname': {'type': 'string',\n    'description': 'Key name for parameters',\n    'default': 'input_schema'},\n   'evalable': {'type': 'boolean',\n    'description': \"stringify defaults that can't be literal_eval'd?\",\n    'default': False},\n   'skip_hidden': {'type': 'boolean',\n    'description': \"skip parameters starting with '_'?\",\n    'default': False},\n   'name': {'type': 'null',\n    'description': \"Override function name (useful for dotted paths like 'obj.method')\",\n    'default': None}},\n  'required': ['f']}}\n\n\n\ndef f(o:object): \"object function\"\n\n\nget_schema(f)\n\n{'name': 'f',\n 'description': 'object function',\n 'input_schema': {'type': 'object',\n  'properties': {'o': {'type': 'object', 'description': ''}},\n  'required': ['o']}}\n\n\n\nclass ClassA:\n    \"I am a class\"\n    def f(self, a:int): # That is `a`\n        \"Do a thing\"\n        return 1\n    def __call__(self, b:str): # That is `b`\n        \"Do another thing\"\n        return 2\n\nca = ClassA()\nca.f(2)\n\n1\n\n\n\nget_schema(ca.f)\n\n{'name': 'f',\n 'description': 'Do a thing',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'That is `a`'}},\n  'required': ['a']}}\n\n\n\nget_schema(ca)\n\n{'name': '__call__',\n 'description': 'Do another thing',\n 'input_schema': {'type': 'object',\n  'properties': {'b': {'type': 'string', 'description': 'That is `b`'}},\n  'required': ['b']}}\n\n\n\n\nUsage examples\nPutting this all together, we can now test getting a schema from silly_sum. The tool use spec doesn’t support return annotations directly, so we put that in the description instead.\n\ns = get_schema(silly_sum)\ndesc = s.pop('description')\nprint(desc)\ns\n\nAdds a + b.\n\nReturns:\n- The sum of the inputs (type: integer)\n\n\n{'name': 'silly_sum',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'First thing to sum'},\n   'b': {'type': 'integer',\n    'description': 'Second thing to sum',\n    'default': 1},\n   'c': {'type': 'array',\n    'description': 'A pointless argument',\n    'items': {'type': 'integer'},\n    'default': None}},\n  'required': ['a']}}\n\n\nThis also works with string annotations, e.g:\n\ndef silly_test(\n    a: 'int',  # quoted type hint\n)-&gt;int:\n    \"Mandatory docstring\"\n    return a\n\nget_schema(silly_test)\n\n{'name': 'silly_test',\n 'description': 'Mandatory docstring\\n\\nReturns:\\n- type: integer',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'quoted type hint'}},\n  'required': ['a']}}\n\n\nThis also works with instance methods:\n\nclass Dummy:\n    def sums(\n        self,\n        a:int,  # First thing to sum\n        b:int=1 # Second thing to sum\n    ): # The sum of the inputs\n        \"Adds a + b.\"\n        print(f\"Finding the sum of {a} and {b}\")\n        return a + b\n\nget_schema(Dummy.sums)\n\n{'name': 'sums',\n 'description': 'Adds a + b.',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'First thing to sum'},\n   'b': {'type': 'integer',\n    'description': 'Second thing to sum',\n    'default': 1}},\n  'required': ['a']}}\n\n\nget_schema also handles more complicated structures such as nested classes. This is useful for things like structured outputs.\n\nclass Turn:\n    \"Turn between two speakers\"\n    def __init__(\n        self,\n        speaker_a:str, # First speaker's message\n        speaker_b:str,  # Second speaker's message\n    ): store_attr()\n\nclass Conversation:\n    \"A conversation between two speakers\"\n    def __init__(\n        self,\n        turns:list[Turn], # Turns of the conversation\n    ): store_attr()\n\nget_schema(Conversation)\n\n{'name': 'Conversation',\n 'description': 'A conversation between two speakers',\n 'input_schema': {'type': 'object',\n  'properties': {'turns': {'type': 'array',\n    'description': 'Turns of the conversation',\n    'items': {'$ref': '#/$defs/Turn'}}},\n  'title': 'Conversation',\n  'required': ['turns'],\n  '$defs': {'Turn': {'type': 'object',\n    'properties': {'speaker_a': {'type': 'string',\n      'description': \"First speaker's message\"},\n     'speaker_b': {'type': 'string',\n      'description': \"Second speaker's message\"}},\n    'title': 'Turn',\n    'required': ['speaker_a', 'speaker_b']}}}}\n\n\n\nclass DictConversation:\n    \"A conversation between two speakers\"\n    def __init__(\n        self,\n        turns:dict[str,list[Turn]], # dictionary of topics and the Turns of the conversation\n    ): store_attr()\n\nget_schema(DictConversation)\n\n{'name': 'DictConversation',\n 'description': 'A conversation between two speakers',\n 'input_schema': {'type': 'object',\n  'properties': {'turns': {'type': 'object',\n    'description': 'dictionary of topics and the Turns of the conversation',\n    'additionalProperties': {'type': 'array',\n     'items': {'$ref': '#/$defs/Turn'}}}},\n  'title': 'DictConversation',\n  'required': ['turns'],\n  '$defs': {'Turn': {'type': 'object',\n    'properties': {'speaker_a': {'type': 'string',\n      'description': \"First speaker's message\"},\n     'speaker_b': {'type': 'string',\n      'description': \"Second speaker's message\"}},\n    'title': 'Turn',\n    'required': ['speaker_a', 'speaker_b']}}}}\n\n\n\nclass SetConversation:\n    \"A conversation between two speakers\"\n    def __init__(\n        self,\n        turns:set[Turn], # the unique Turns of the conversation\n    ): store_attr()\n\nget_schema(SetConversation)\n\n{'name': 'SetConversation',\n 'description': 'A conversation between two speakers',\n 'input_schema': {'type': 'object',\n  'properties': {'turns': {'type': 'array',\n    'description': 'the unique Turns of the conversation',\n    'items': {'$ref': '#/$defs/Turn'},\n    'uniqueItems': True}},\n  'title': 'SetConversation',\n  'required': ['turns'],\n  '$defs': {'Turn': {'type': 'object',\n    'properties': {'speaker_a': {'type': 'string',\n      'description': \"First speaker's message\"},\n     'speaker_b': {'type': 'string',\n      'description': \"Second speaker's message\"}},\n    'title': 'Turn',\n    'required': ['speaker_a', 'speaker_b']}}}}\n\n\n\n\nAdditional get_schema() Test Cases\nUnion types are approximately mapped to JSON schema ‘anyOf’ with two or more value types.\n\ndef _union_test(opt_tup: Union[Tuple[int, int], str, int]=None):\n    \"Mandatory docstring\"\n    return \"\"\nget_schema(_union_test)\n\n{'name': '_union_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'opt_tup': {'type': 'object',\n    'description': '',\n    'default': None,\n    'anyOf': [{'type': 'array', 'items': {}},\n     {'type': 'string'},\n     {'type': 'integer'}]}}}}\n\n\nThe new (Python 3.10+) union syntax can also be used, producing an equivalent schema.\n\ndef _new_union_test(opt_tup: Tuple[int, int] | str | int =None):\n    \"Mandatory docstring\"\n    pass\nget_schema(_new_union_test)\n\n{'name': '_new_union_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'opt_tup': {'type': 'object',\n    'description': '',\n    'default': None,\n    'anyOf': [{'type': 'array', 'items': {}},\n     {'type': 'string'},\n     {'type': 'integer'}]}}}}\n\n\nOptional is a special case of union types, limited to two types, one of which is None (mapped to null in JSON schema):\n\ndef _optional_test(opt_tup: Optional[Tuple[int, int]]=None):\n    \"Mandatory docstring\"\n    pass\nget_schema(_optional_test)\n\n{'name': '_optional_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'opt_tup': {'type': 'object',\n    'description': '',\n    'default': None,\n    'anyOf': [{'type': 'array', 'items': {}}, {'type': 'null'}]}}}}\n\n\nContainers can also be used, both in their parameterized form (List[int]) or as their unparameterized raw type (List). In the latter case, the item type is mapped to object in JSON schema.\n\ndef _list_test(l: List[int]):\n    \"Mandatory docstring\"\n    pass\nget_schema(_list_test)\n\n{'name': '_list_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'l': {'type': 'array',\n    'description': '',\n    'items': {'type': 'integer'}}},\n  'required': ['l']}}\n\n\n\ndef _raw_list_test(l: List):\n    \"Mandatory docstring\"\n    pass\nget_schema(_raw_list_test)\n\n{'name': '_raw_list_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'l': {'type': 'array', 'description': '', 'items': {}}},\n  'required': ['l']}}\n\n\nThe same applies to dictionary, which can similarly be parameterized with key/value types or specified as a raw type.\n\ndef _dict_test(d: Dict[str, int]):\n    \"Mandatory docstring\"\n    pass\nget_schema(_dict_test)\n\n{'name': '_dict_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'d': {'type': 'object',\n    'description': '',\n    'additionalProperties': {'type': 'integer'}}},\n  'required': ['d']}}\n\n\n\ndef _raw_dict_test(d: Dict):\n    \"Mandatory docstring\"\nget_schema(_raw_dict_test)\n\n{'name': '_raw_dict_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'d': {'type': 'object', 'description': ''}},\n  'required': ['d']}}\n\n\n\ndef _path_test(path: Path = Path('.')):\n    \"Mandatory docstring\"\nget_schema(_path_test)\n\n{'name': '_path_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'path': {'type': 'string',\n    'description': '',\n    'default': Path('.'),\n    'format': 'Path'}}}}\n\n\nSchemas that need to be converted using ast.literal_eval will fail with non-primitive defaults:\n\ntest_fail(lambda: ast.literal_eval(str(get_schema(_path_test))), exc=ValueError)\n\nUse evalable to have those defaults stringified:\n\ndef _path_test(path: Path = Path('.')):\n    \"Mandatory docstring\"\nget_schema(_path_test, evalable=True)\n\n{'name': '_path_test',\n 'description': 'Mandatory docstring',\n 'input_schema': {'type': 'object',\n  'properties': {'path': {'type': 'string',\n    'description': '',\n    'default': '.',\n    'format': 'Path'}}}}\n\n\nUse skip_hidden to exclude parameters starting with _ from the schema:\n\ndef test_hidden(a: int, _internal: str = \"x\"):\n    \"Test func\"\n    pass\n\nget_schema(test_hidden, skip_hidden=True)  # should exclude _internal\n\n{'name': 'test_hidden',\n 'description': 'Test func',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': ''}},\n  'required': ['a']}}\n\n\n\nget_schema(test_hidden)\n\n{'name': 'test_hidden',\n 'description': 'Test func',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': ''},\n   '_internal': {'type': 'string', 'description': '', 'default': 'x'}},\n  'required': ['a']}}\n\n\n\n\nPython tool\nIn language model clients it’s often useful to have a ‘code interpreter’ – this is something that runs code, and generally outputs the result of the last expression (i.e like IPython or Jupyter).\nIn this section we’ll create the python function, which executes a string as Python code, with an optional timeout. If the last line is an expression, we’ll return that – just like in IPython or Jupyter, but without needing them installed.\n\n\nExported source\nimport ast, time, signal, traceback\nfrom fastcore.utils import *\n\n\n\n\nExported source\ndef _copy_loc(new, orig):\n    \"Copy location information from original node to new node and all children.\"\n    new = ast.copy_location(new, orig)\n    for field, o in ast.iter_fields(new):\n        if isinstance(o, ast.AST): setattr(new, field, _copy_loc(o, orig))\n        elif isinstance(o, list): setattr(new, field, [_copy_loc(value, orig) for value in o])\n    return new\n\n\nThis is an internal function that’s needed for _run to ensure that location information is available in the abstract syntax tree (AST), since otherwise python complains.\n\n\nExported source\ndef _run(code:str, glb:dict=None, loc:dict=None):\n    \"Run `code`, returning final expression (similar to IPython)\"\n    tree = ast.parse(code)\n    last_node = tree.body[-1] if tree.body else None\n    \n    # If the last node is an expression, modify the AST to capture the result\n    if isinstance(last_node, ast.Expr):\n        tgt = [ast.Name(id='_result', ctx=ast.Store())]\n        assign_node = ast.Assign(targets=tgt, value=last_node.value)\n        tree.body[-1] = _copy_loc(assign_node, last_node)\n\n    compiled_code = compile(tree, filename='&lt;ast&gt;', mode='exec')\n    glb = glb or {}\n    stdout_buffer = io.StringIO()\n    saved_stdout = sys.stdout\n    sys.stdout = stdout_buffer\n    try: exec(compiled_code, glb, loc)\n    finally: sys.stdout = saved_stdout\n    _result = glb.get('_result', None)\n    if _result is not None: return _result\n    return stdout_buffer.getvalue().strip()\n\n\nThis is the internal function used to actually run the code – we pull off the last AST to see if it’s an expression (i.e something that returns a value), and if so, we store it to a special _result variable so we can return it.\n\n_run('import math;math.factorial(12)')\n\n479001600\n\n\n\n_run('print(1+1)')\n\n'2'\n\n\nWe now have the machinery needed to create our python function.\n\nsource\n\n\npython\n\ndef python(\n    code:str, # Code to execute\n    glb:Optional=None, # Globals namespace\n    loc:Optional=None, # Locals namespace\n    timeout:int=3600, # Maximum run time in seconds\n):\n\nExecutes python code with timeout and returning final expression (similar to IPython).\n\n\nExported source\ndef python(\n    code:str, # Code to execute\n    glb:Optional[dict]=None, # Globals namespace\n    loc:Optional[dict]=None, # Locals namespace\n    timeout:int=3600 # Maximum run time in seconds\n):\n    \"Executes python `code` with `timeout` and returning final expression (similar to IPython).\"\n    def handler(*args): raise TimeoutError()\n    if glb is None: glb = inspect.currentframe().f_back.f_globals\n    if loc is None: loc=glb\n    signal.signal(signal.SIGALRM, handler)\n    signal.alarm(timeout)\n    try: return _run(code, glb, loc)\n    except Exception as e: return traceback.format_exc()\n    finally: signal.alarm(0)\n\n\nThere’s no builtin security here – you should generally use this in a sandbox, or alternatively prompt before running code. It can handle multiline function definitions, and pretty much any other normal Python syntax.\n\npython(\"\"\"def factorial(n):\n    if n == 0 or n == 1: return 1\n    else: return n * factorial(n-1)\nfactorial(5)\"\"\")\n\n120\n\n\nIf the code takes longer than timeout then it returns an error string.\n\nprint(python('import time; time.sleep(10)', timeout=1))\n\nTraceback (most recent call last):\n  File \"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_37749/2052945749.py\", line 14, in python\n    try: return _run(code, glb, loc)\n                ^^^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_37749/1858893181.py\", line 18, in _run\n    try: exec(compiled_code, glb, loc)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"&lt;ast&gt;\", line 1, in &lt;module&gt;\n  File \"/var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_37749/2052945749.py\", line 9, in handler\n    def handler(*args): raise TimeoutError()\n                        ^^^^^^^^^^^^^^^^^^^^\nTimeoutError\n\n\n\nBy default the caller’s global namespace is used.\n\npython(\"a=1\")\na\n\n1\n\n\nPass a different glb if needed; this requires using python_ns.\n\nglb = {}\npython(\"a=3\", glb=glb)\na, glb['a']\n\n(1, 3)\n\n\n\nget_schema(python)\n\n{'name': 'python',\n 'description': 'Executes python `code` with `timeout` and returning final expression (similar to IPython).',\n 'input_schema': {'type': 'object',\n  'properties': {'code': {'type': 'string', 'description': 'Code to execute'},\n   'glb': {'type': 'object',\n    'description': 'Globals namespace',\n    'default': None,\n    'anyOf': [{'type': 'object'}, {'type': 'null'}]},\n   'loc': {'type': 'object',\n    'description': 'Locals namespace',\n    'default': None,\n    'anyOf': [{'type': 'object'}, {'type': 'null'}]},\n   'timeout': {'type': 'integer',\n    'description': 'Maximum run time in seconds',\n    'default': 3600}},\n  'required': ['code']}}\n\n\n\n\nTool Calling\nMany LLM API providers offer tool calling where an LLM can choose to call a given tool. This is also helpful for structured outputs since the response from the LLM is contrained to the required arguments of the tool.\nThis section will be dedicated to helper functions for calling tools. We don’t want to allow LLMs to call just any possible function (that would be a security disaster!) so we create a namespace – that is, a dictionary of allowable function names to call.\n\nsource\n\n\nmk_ns\n\ndef mk_ns(\n    fs\n):\n\n\ndef sums(a, b): return a + b\nns = mk_ns(sums); ns\n\n{'sums': &lt;function __main__.sums(a, b)&gt;}\n\n\n\nns['sums'](1, 2)\n\n3\n\n\n\nca = ClassA()\n\n\nsource\n\n\nresolve_nm\n\ndef resolve_nm(\n    nm, ns\n):\n\n\ntest_eq(resolve_nm('ca.f', globals()), ca.f)\n\n\nsource\n\n\nget_schema_nm\n\ndef get_schema_nm(\n    nm:str, ns, dot2dash:bool=False, kwargs:VAR_KEYWORD\n):\n\nGet schema for symbol nm in namespace ns, preserving the full dotted name\n\nschema = get_schema_nm('ca.f', locals())\ntest_eq(schema['name'], 'ca.f')\nschema\n\n{'name': 'ca.f',\n 'description': 'Do a thing',\n 'input_schema': {'type': 'object',\n  'properties': {'a': {'type': 'integer', 'description': 'That is `a`'}},\n  'required': ['a']}}\n\n\n\nsource\n\n\ncall_func\n\ndef call_func(\n    fc_name, fc_inputs, ns, raise_on_err:bool=True\n):\n\nCall the function fc_name with the given fc_inputs using namespace ns.\nNow when we an LLM responses with the tool to use and its inputs, we can simply use the same namespace it was given to look up the tool and call it.\n\ncall_func('sums', {'a': 1, 'b': 2}, ns=[sums])\n\n3\n\n\n\nassert \"unsupported operand type(s) for +: 'int' and 'str'\" in call_func('sums', {'a': 1, 'b': '3'}, ns=ns, raise_on_err=False)\n\n\ntest_fail(call_func, args=['sums', {'a': 1, 'b': '3'}], kwargs={'ns': ns})\n\nTypes that can be constructed from a plain str can be used directly, as long as they are in custom_types (which you can add to).\n\ndef path_test(\n    a: Path,  # a type hint\n    b: Path   # b type hint\n):\n    \"Mandatory docstring\"\n    return a/b\n\ntest_eq(call_func('path_test', {'a': '/home', 'b': 'user'}, ns=[path_test]), Path('/home/user'))\n\n\ntest_eq(call_func('ca.f', {'a': 5}, ns=globals()), 1)\n\n\n\nAsync function calling\n\nasync def asums(a, b): return a + b\nns = mk_ns(asums); ns\n\n{'asums': &lt;function __main__.asums(a, b)&gt;}\n\n\n\nsource\n\n\ncall_func_async\n\nasync def call_func_async(\n    fc_name, fc_inputs, ns, raise_on_err:bool=True\n):\n\nAwaits the function fc_name with the given fc_inputs using namespace ns.\n\n\nExported source\nasync def call_func_async(fc_name, fc_inputs, ns, raise_on_err=True):\n    \"Awaits the function `fc_name` with the given `fc_inputs` using namespace `ns`.\"\n    if not isinstance(ns, abc.Mapping): ns = mk_ns(ns)\n    func = resolve_nm(fc_name, ns)\n    try:\n        res = call_func(fc_name, fc_inputs, ns, raise_on_err=raise_on_err)\n        res = await maybe_await(res)\n    except Exception as e:\n        if raise_on_err: raise e from None\n        else: return traceback.format_exc()\n    return res\n\n\nTesting async call_func_async both with sync and async functions. Sync functions are automatically run in a separate thread via asyncio.to_thread, allowing asyncio.gather to execute multiple sync tool calls in parallel without blocking the event loop.\n\ntest_eq(await call_func_async('asums', {'a': 1, 'b': 2}, ns=[asums]), 3)\n\n\ntest_eq(await call_func_async('sums', {'a': 1, 'b': 2}, ns=[sums]), 3)\n\n\nr = await call_func_async('asums', {'a': 1, 'b': '2'}, ns=[asums], raise_on_err=False)\nassert \"unsupported operand type(s) for +: 'int' and 'str'\" in r\n\n\nex = False\ntry: await call_func_async('asums', {'a': 1, 'b': '2'}, ns=[asums], raise_on_err=True)\nexcept: ex = True\nassert ex\n\n\nclass B:\n    async def g(self, x:int): return x*2\n\nb = B()\nres = await call_func_async('b.g', {'x': 5}, ns=globals())\ntest_eq(res, 10)",
    "crumbs": [
      "funccall source"
    ]
  },
  {
    "objectID": "funccall.html#schema-to-function",
    "href": "funccall.html#schema-to-function",
    "title": "funccall source",
    "section": "Schema to function",
    "text": "Schema to function\n\ntype_map = {'string': str, 'boolean': bool, 'integer': int, 'number': float, 'array': list, 'object': dict}\n\n\nsource\n\nmk_param\n\ndef mk_param(\n    nm, props, req\n):\n\nCreate a Parameter for nm with schema props\n\ntool = dict2obj({\n    'description': 'Find real-…',\n    'inputSchema': { '$schema': 'http://json-schema.org/draft-07/schema#',\n                   'additionalProperties': False,\n                   'properties': { 'language': { 'description': 'Filter by …', 'items': {'type': 'string'}, 'type': 'array'},\n                                   'matchCase': {'default': False, 'description': 'Whether th…', 'type': 'boolean'},\n                                   'path': {'description': 'Filter by …', 'type': 'string'},\n                                   'query': {'description': 'The litera…', 'type': 'string'},\n                                   'useRegexp': {'default': False, 'description': 'Whether to…', 'type': 'boolean'}},\n                   'required': ['query'], 'type': 'object'},\n    'name': 'searchGitHub'\n})\n\n\nprops, req = tool.inputSchema['properties'], tool.inputSchema['required']\nlist(props)\n\n['language', 'matchCase', 'path', 'query', 'useRegexp']\n\n\n\nprops.matchCase\n\n{'default': False, 'description': 'Whether th…', 'type': 'boolean'}\n\n\n\np = mk_param('query', props.query, req)\np, p.kind\n\n(&lt;Parameter \"query: str\"&gt;, &lt;_ParameterKind.POSITIONAL_OR_KEYWORD: 1&gt;)\n\n\n\np = mk_param('language', props.language, req)\np, p.kind\n\n(&lt;Parameter \"language: list[str] = None\"&gt;, &lt;_ParameterKind.KEYWORD_ONLY: 3&gt;)\n\n\n\nsource\n\n\nschema2sig\n\ndef schema2sig(\n    tool\n):\n\nConvert json schema tool to a Signature\n\nschema2sig(tool)\n\n&lt;Signature (query: str, *, language: list[str] = None, matchCase: bool = False, path: str = None, useRegexp: bool = False)&gt;\n\n\n\nsource\n\n\nmk_tool\n\ndef mk_tool(\n    dispfn, tool\n):\n\nCreate a callable function from a JSON schema tool definition\nmk_tool is the inverse of get_schema — it creates a callable Python function from a JSON schema tool definition. This is useful for MCP clients where tools are defined as schemas but need to be called as regular Python functions.\nThe created function has a proper signature, docstring, and annotations, so it works well with IDE autocomplete and introspection.\n\ndef dispatch_eg(name, **kwargs): return f\"Called {name} with {kwargs}\"\n\nfn = mk_tool(dispatch_eg, tool)\nfn('hello', path='src/')\n\n\"Called searchGitHub with {'query': 'hello', 'path': 'src/'}\"",
    "crumbs": [
      "funccall source"
    ]
  },
  {
    "objectID": "md_hier.html",
    "href": "md_hier.html",
    "title": "Markdown Hierarchy Parser",
    "section": "",
    "text": "from toolslm.md_hier import *\nfrom IPython.display import Markdown\nThe md_hier module provides utilities for parsing markdown documents and converting them into structured hierarchical dictionaries. This is particularly useful for processing documentation, extracting sections, or navigating complex markdown files programmatically.",
    "crumbs": [
      "Markdown Hierarchy Parser"
    ]
  },
  {
    "objectID": "md_hier.html#overview",
    "href": "md_hier.html#overview",
    "title": "Markdown Hierarchy Parser",
    "section": "Overview",
    "text": "Overview\nThe module provides a main function and supporting class: - create_heading_dict: Creates a nested dictionary structure matching the markdown hierarchy\n- HeadingDict: A dictionary-like object that also stores the markdown text content\nThe function handles code blocks properly by ignoring headings that appear within fenced code blocks.\n\n\ncreate_heading_dict\n\ndef create_heading_dict(\n    text, rm_fenced:bool=True\n):\n\nCreate a nested dictionary structure from markdown headings.\n\nsample_md = \"\"\"\n# Introduction\n\nWelcome to our documentation.\n\n## Getting Started\n\nFollow these steps to begin.\n\n### Installation\n\nRun the following command:\n\n```bash\n# Install the packackge\npip install our-package\n```\n\n### Configuration\n\nSet up your config file.\n\n## Advanced Usage\n\nFor advanced users only.\n\n# Appendix\n\nAdditional resources.\"\"\"\n\n\nresult = create_heading_dict(sample_md)\nprint(\"Available sections:\")\nfor key in result.keys(): print(f\"  {key}\")\nprint(f\"\\nRoot document has {len(result.text)} characters of text\")\n\nAvailable sections:\n  Introduction\n  Appendix\n\nRoot document has 328 characters of text\n\n\nYou can access any section’s content via the text attribute:\n\nprint(result['Introduction']['Getting Started']['Installation'].text)\n\n### Installation\n\nRun the following command:\n\n```bash\n# Install the packackge\n\n\nNotice how parent sections contain all their child content in their text attribute:\n\nprint(result['Introduction']['Getting Started'].text[:200] + \"…\")\n\n## Getting Started\n\nFollow these steps to begin.\n\n### Installation\n\nRun the following command:\n\n```bash\n# Install the packackge\npip install our-package\n```\n\n### Configuration…\n\n\ncreate_heading_dict creates a nested dictionary structure that mirrors the markdown hierarchy. Each heading becomes a dictionary key containing its subheadings.\n\nNested structure: Creates a tree-like dictionary hierarchy\nNavigation friendly: Easy to traverse programmatically\nCode block filtering: Removes code blocks before processing\n\nLet’s see the nested structure:\n\nresult = create_heading_dict(sample_md)\nprint(\"Structure:\")\nprint(f\"Root keys: {list(result.keys())}\")\nprint(f\"Introduction subkeys: {list(result['Introduction'].keys())}\")\nprint(f\"Getting Started subkeys: {list(result['Introduction']['Getting Started'].keys())}\")\n\nprint(f\"\\nType of result: {type(result)}\")\nprint(f\"Type of subsection: {type(result['Introduction'])}\")\nprint(f\"Has text attribute: {hasattr(result, 'text')}\")\n\nStructure:\nRoot keys: ['Introduction', 'Appendix']\nIntroduction subkeys: ['Getting Started', 'Advanced Usage']\nGetting Started subkeys: ['Installation', 'Configuration']\n\nType of result: &lt;class 'toolslm.md_hier.HeadingDict'&gt;\nType of subsection: &lt;class 'toolslm.md_hier.HeadingDict'&gt;\nHas text attribute: True\n\n\n\n\nBenefits\nThis approach provides the best of both worlds:\nStructure Navigation: Navigate the document hierarchy naturally using dictionary keys - result['Introduction']['Getting Started'] - Check section existence with 'section' in result - Iterate through subsections with result.keys()\nContent Access: Get the actual markdown text at any level - result.text - entire document\n- result['Introduction'].text - section with all subsections - result['Introduction']['Getting Started']['Installation'].text - specific subsection only\nUse Cases: - Documentation processing: Extract specific sections while preserving formatting - Content analysis: Analyze document structure and section lengths\n- Template generation: Build navigation interfaces from document structure - Section extraction: Pull out individual sections with their complete content",
    "crumbs": [
      "Markdown Hierarchy Parser"
    ]
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Release notes",
    "section": "",
    "text": "look for __dialog_name (#78)\n\n\n\n\n\n\n\n\nSkip builtin types (e.g. object) from nested schema generation (#77)\nrun sync tools with threads in call_func_async (#73), thanks to @KeremTurgutlu\n\n\n\n\n\n\n\n\nrun sync tools with threads in call_func_async (#73), thanks to @KeremTurgutlu\n\n\n\n\n\n\n\n\nUse callable class docstring when __call__ lacks one (#71)\n\n\n\n\n\n\n\n\nAdd dotted name support for resolving and calling methods on objects (#70)\n\n\n\n\n\nAdd ‘items’ field to JSON schema for Gemini compatibility (#68), thanks to @PiotrCzapla\n\n\n\n\n\n\n\n\nAdd @llmtool decorators to inspecttools functions and improve type hints (#67)\n\n\n\n\n\n\n\n\nAdd inspecttools module for LLM symbol inspection (#66)\nUse codesigs for signatures (#66)\n\n\n\n\n\n\n\n\nAdd UnionType support to get_schema (#65)\n\n\n\n\n\n\n\n\nget_schema fails if return docment but no type (#64)\n\n\n\n\n\n\n\n\nAdd repo2ctx CLI command (#63)\n\n\n\n\n\n\n\n\nDefault folder2ctx_cli to current folder (#62)\n\n\n\n\n\n\n\n\nAdd return docments to schema (#61)\n\n\n\n\n\n\nline numbers support, raw cells, and expanduser for ~ paths\n\n\n\n\n\n\n\nAdd sigs_only (#60)\n\n\n\n\n\n\n\n\nAdd ids to ctx funcs (#59)\n\n\n\n\n\n\n\n\nmissing import ghapi (#58)\n\n\n\n\n\n\n\n\nAdd sym2{file,folder,pkg}ctx (#57)\n\n\n\n\n\n\n\n\nMuch improved repo2ctx (#56)\n\n\n\n\n\n\n\n\nAdd skip_hidden (#55)\n\n\n\n\n\n\n\n\nAdd evalable to get_schema (#54)\n\n\n\n\n\n\n\n\nAdd max_size and title to folder2ctx et al (#53)\n\n\n\n\n\n\n\n\nAdd repo2ctx (#52)\n\n\n\n\n\n\n\n\nAdd folder2ctx out param (#51)\n\n\n\n\n\n\n\n\nAutomatically handle {Path, bytes, Decimal, UUID} in schemas (#49)\nAdd schema to function capabilities (#47)\n\n\n\n\n\nfix line misalignment when code block is between headings (#40), thanks to @jackhogan\n\n\n\n\n\n\n\n\nSupport notebook context (#41)\nOnly add title when needed to schemas (#39)\n\n\n\n\n\n\n\n\nNew combined API (#38)\n\n\n\n\n\n\n\n\nAdd rm_fenced (#37)\n\n\n\n\n\nAdd edge case tests and fix them (#36)\n\n\n\n\n\n\n\n\nRemove object enumeration of tools (#35)\n\n\n\n\n\n\n\n\nHandle list and dict args to mk_ns (#34)\n\n\n\n\n\n\n\n\nAuto clean up bad param names in call_func (#33)\n\n\n\n\n\npython() function can’t be used as a tool (#32)\n\n\n\n\n\n\n\n\nOptionally dont raise error on call_func (#31), thanks to @erikgaas\ndict support in get_schema (#30)\n\n\n\n\n\n\n\n\nOptional libs (http2text, beautifulsoup, llms_txt) are no longer automatically installed\n\n\n\n\n\nLazily load optional modules (#29)\n\n\n\n\n\n\n\n\nPass glb,loc to python (#28)\n\n\n\n\n\n\n\n\nAdds call_func_async (#27), thanks to @mikonapoli\nAdd arg ignore links (#26), thanks to @Isaac-Flath\n\n\n\n\n\n\n\n\nAdd arg ignore links (#26), thanks to @Isaac-Flath\n\n\n\n\n\nfix: prevent markdown heading detection inside code blocks (#25), thanks to @franckalbinet\nFix markdown hierarchy parsing for arbitrary header levels (#22), thanks to @erikgaas\n\n\n\n\n\n\n\n\nReplace source with src in context generation (#17)\n\n\n\n\n\n\n\n\nEscape and print context in folder2ctx et al (#16)\n\n\n\n\n\n\n\n\nAdd dict2obj to md_hier funcs (#15)\nMigrate call_func from claudette to toolslm (#14), thanks to @ncoop57\nAllow for getting schemas from nested structures (#11), thanks to @ncoop57\nAllow for sel to select and wrap multiple element results (#10), thanks to @Isaac-Flath\n\n\n\n\n\nUsing get_schema on class method results in type missing error (#12)\n\n\n\n\n\n\n\n\nAdd read_docs and find_docs (#8)\n\n\n\n\n\n\n\n\nXML tools assume all files have content (#3)\n\n\n\n\n\n\nMinor updates\n\n\n\n\n\nRename project\n\n\n\n\n\nInitial alpha release"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Release notes",
    "section": "",
    "text": "look for __dialog_name (#78)"
  },
  {
    "objectID": "CHANGELOG.html#section-1",
    "href": "CHANGELOG.html#section-1",
    "title": "Release notes",
    "section": "",
    "text": "Skip builtin types (e.g. object) from nested schema generation (#77)\nrun sync tools with threads in call_func_async (#73), thanks to @KeremTurgutlu"
  },
  {
    "objectID": "CHANGELOG.html#section-2",
    "href": "CHANGELOG.html#section-2",
    "title": "Release notes",
    "section": "",
    "text": "run sync tools with threads in call_func_async (#73), thanks to @KeremTurgutlu"
  },
  {
    "objectID": "CHANGELOG.html#section-3",
    "href": "CHANGELOG.html#section-3",
    "title": "Release notes",
    "section": "",
    "text": "Use callable class docstring when __call__ lacks one (#71)"
  },
  {
    "objectID": "CHANGELOG.html#section-4",
    "href": "CHANGELOG.html#section-4",
    "title": "Release notes",
    "section": "",
    "text": "Add dotted name support for resolving and calling methods on objects (#70)\n\n\n\n\n\nAdd ‘items’ field to JSON schema for Gemini compatibility (#68), thanks to @PiotrCzapla"
  },
  {
    "objectID": "CHANGELOG.html#section-5",
    "href": "CHANGELOG.html#section-5",
    "title": "Release notes",
    "section": "",
    "text": "Add @llmtool decorators to inspecttools functions and improve type hints (#67)"
  },
  {
    "objectID": "CHANGELOG.html#section-6",
    "href": "CHANGELOG.html#section-6",
    "title": "Release notes",
    "section": "",
    "text": "Add inspecttools module for LLM symbol inspection (#66)\nUse codesigs for signatures (#66)"
  },
  {
    "objectID": "CHANGELOG.html#section-7",
    "href": "CHANGELOG.html#section-7",
    "title": "Release notes",
    "section": "",
    "text": "Add UnionType support to get_schema (#65)"
  },
  {
    "objectID": "CHANGELOG.html#section-8",
    "href": "CHANGELOG.html#section-8",
    "title": "Release notes",
    "section": "",
    "text": "get_schema fails if return docment but no type (#64)"
  },
  {
    "objectID": "CHANGELOG.html#section-9",
    "href": "CHANGELOG.html#section-9",
    "title": "Release notes",
    "section": "",
    "text": "Add repo2ctx CLI command (#63)"
  },
  {
    "objectID": "CHANGELOG.html#section-10",
    "href": "CHANGELOG.html#section-10",
    "title": "Release notes",
    "section": "",
    "text": "Default folder2ctx_cli to current folder (#62)"
  },
  {
    "objectID": "CHANGELOG.html#section-11",
    "href": "CHANGELOG.html#section-11",
    "title": "Release notes",
    "section": "",
    "text": "Add return docments to schema (#61)"
  },
  {
    "objectID": "CHANGELOG.html#section-12",
    "href": "CHANGELOG.html#section-12",
    "title": "Release notes",
    "section": "",
    "text": "line numbers support, raw cells, and expanduser for ~ paths"
  },
  {
    "objectID": "CHANGELOG.html#section-13",
    "href": "CHANGELOG.html#section-13",
    "title": "Release notes",
    "section": "",
    "text": "Add sigs_only (#60)"
  },
  {
    "objectID": "CHANGELOG.html#section-14",
    "href": "CHANGELOG.html#section-14",
    "title": "Release notes",
    "section": "",
    "text": "Add ids to ctx funcs (#59)"
  },
  {
    "objectID": "CHANGELOG.html#section-15",
    "href": "CHANGELOG.html#section-15",
    "title": "Release notes",
    "section": "",
    "text": "missing import ghapi (#58)"
  },
  {
    "objectID": "CHANGELOG.html#section-16",
    "href": "CHANGELOG.html#section-16",
    "title": "Release notes",
    "section": "",
    "text": "Add sym2{file,folder,pkg}ctx (#57)"
  },
  {
    "objectID": "CHANGELOG.html#section-17",
    "href": "CHANGELOG.html#section-17",
    "title": "Release notes",
    "section": "",
    "text": "Much improved repo2ctx (#56)"
  },
  {
    "objectID": "CHANGELOG.html#section-18",
    "href": "CHANGELOG.html#section-18",
    "title": "Release notes",
    "section": "",
    "text": "Add skip_hidden (#55)"
  },
  {
    "objectID": "CHANGELOG.html#section-19",
    "href": "CHANGELOG.html#section-19",
    "title": "Release notes",
    "section": "",
    "text": "Add evalable to get_schema (#54)"
  },
  {
    "objectID": "CHANGELOG.html#section-20",
    "href": "CHANGELOG.html#section-20",
    "title": "Release notes",
    "section": "",
    "text": "Add max_size and title to folder2ctx et al (#53)"
  },
  {
    "objectID": "CHANGELOG.html#section-21",
    "href": "CHANGELOG.html#section-21",
    "title": "Release notes",
    "section": "",
    "text": "Add repo2ctx (#52)"
  },
  {
    "objectID": "CHANGELOG.html#section-22",
    "href": "CHANGELOG.html#section-22",
    "title": "Release notes",
    "section": "",
    "text": "Add folder2ctx out param (#51)"
  },
  {
    "objectID": "CHANGELOG.html#section-23",
    "href": "CHANGELOG.html#section-23",
    "title": "Release notes",
    "section": "",
    "text": "Automatically handle {Path, bytes, Decimal, UUID} in schemas (#49)\nAdd schema to function capabilities (#47)\n\n\n\n\n\nfix line misalignment when code block is between headings (#40), thanks to @jackhogan"
  },
  {
    "objectID": "CHANGELOG.html#section-24",
    "href": "CHANGELOG.html#section-24",
    "title": "Release notes",
    "section": "",
    "text": "Support notebook context (#41)\nOnly add title when needed to schemas (#39)"
  },
  {
    "objectID": "CHANGELOG.html#section-25",
    "href": "CHANGELOG.html#section-25",
    "title": "Release notes",
    "section": "",
    "text": "New combined API (#38)"
  },
  {
    "objectID": "CHANGELOG.html#section-26",
    "href": "CHANGELOG.html#section-26",
    "title": "Release notes",
    "section": "",
    "text": "Add rm_fenced (#37)\n\n\n\n\n\nAdd edge case tests and fix them (#36)"
  },
  {
    "objectID": "CHANGELOG.html#section-27",
    "href": "CHANGELOG.html#section-27",
    "title": "Release notes",
    "section": "",
    "text": "Remove object enumeration of tools (#35)"
  },
  {
    "objectID": "CHANGELOG.html#section-28",
    "href": "CHANGELOG.html#section-28",
    "title": "Release notes",
    "section": "",
    "text": "Handle list and dict args to mk_ns (#34)"
  },
  {
    "objectID": "CHANGELOG.html#section-29",
    "href": "CHANGELOG.html#section-29",
    "title": "Release notes",
    "section": "",
    "text": "Auto clean up bad param names in call_func (#33)\n\n\n\n\n\npython() function can’t be used as a tool (#32)"
  },
  {
    "objectID": "CHANGELOG.html#section-30",
    "href": "CHANGELOG.html#section-30",
    "title": "Release notes",
    "section": "",
    "text": "Optionally dont raise error on call_func (#31), thanks to @erikgaas\ndict support in get_schema (#30)"
  },
  {
    "objectID": "CHANGELOG.html#section-31",
    "href": "CHANGELOG.html#section-31",
    "title": "Release notes",
    "section": "",
    "text": "Optional libs (http2text, beautifulsoup, llms_txt) are no longer automatically installed\n\n\n\n\n\nLazily load optional modules (#29)"
  },
  {
    "objectID": "CHANGELOG.html#section-32",
    "href": "CHANGELOG.html#section-32",
    "title": "Release notes",
    "section": "",
    "text": "Pass glb,loc to python (#28)"
  },
  {
    "objectID": "CHANGELOG.html#section-33",
    "href": "CHANGELOG.html#section-33",
    "title": "Release notes",
    "section": "",
    "text": "Adds call_func_async (#27), thanks to @mikonapoli\nAdd arg ignore links (#26), thanks to @Isaac-Flath"
  },
  {
    "objectID": "CHANGELOG.html#section-34",
    "href": "CHANGELOG.html#section-34",
    "title": "Release notes",
    "section": "",
    "text": "Add arg ignore links (#26), thanks to @Isaac-Flath\n\n\n\n\n\nfix: prevent markdown heading detection inside code blocks (#25), thanks to @franckalbinet\nFix markdown hierarchy parsing for arbitrary header levels (#22), thanks to @erikgaas"
  },
  {
    "objectID": "CHANGELOG.html#section-35",
    "href": "CHANGELOG.html#section-35",
    "title": "Release notes",
    "section": "",
    "text": "Replace source with src in context generation (#17)"
  },
  {
    "objectID": "CHANGELOG.html#section-36",
    "href": "CHANGELOG.html#section-36",
    "title": "Release notes",
    "section": "",
    "text": "Escape and print context in folder2ctx et al (#16)"
  },
  {
    "objectID": "CHANGELOG.html#section-37",
    "href": "CHANGELOG.html#section-37",
    "title": "Release notes",
    "section": "",
    "text": "Add dict2obj to md_hier funcs (#15)\nMigrate call_func from claudette to toolslm (#14), thanks to @ncoop57\nAllow for getting schemas from nested structures (#11), thanks to @ncoop57\nAllow for sel to select and wrap multiple element results (#10), thanks to @Isaac-Flath\n\n\n\n\n\nUsing get_schema on class method results in type missing error (#12)"
  },
  {
    "objectID": "CHANGELOG.html#section-38",
    "href": "CHANGELOG.html#section-38",
    "title": "Release notes",
    "section": "",
    "text": "Add read_docs and find_docs (#8)"
  },
  {
    "objectID": "CHANGELOG.html#section-39",
    "href": "CHANGELOG.html#section-39",
    "title": "Release notes",
    "section": "",
    "text": "XML tools assume all files have content (#3)"
  },
  {
    "objectID": "CHANGELOG.html#section-40",
    "href": "CHANGELOG.html#section-40",
    "title": "Release notes",
    "section": "",
    "text": "Minor updates"
  },
  {
    "objectID": "CHANGELOG.html#section-41",
    "href": "CHANGELOG.html#section-41",
    "title": "Release notes",
    "section": "",
    "text": "Rename project"
  },
  {
    "objectID": "CHANGELOG.html#section-42",
    "href": "CHANGELOG.html#section-42",
    "title": "Release notes",
    "section": "",
    "text": "Initial alpha release"
  },
  {
    "objectID": "download.html",
    "href": "download.html",
    "title": "Download helpers",
    "section": "",
    "text": "from IPython.display import Markdown,HTML\nfrom fastcore.test import *\n\n\nsource\n\nclean_md\n\ndef clean_md(\n    text, rm_comments:bool=True, rm_details:bool=True\n):\n\nRemove comments and &lt;details&gt; sections from text\n\nsource\n\n\nread_md\n\ndef read_md(\n    url, rm_comments:bool=True, rm_details:bool=True, params:QueryParamTypes | None=None,\n    headers:HeaderTypes | None=None, cookies:CookieTypes | None=None, auth:AuthTypes | None=None,\n    proxy:ProxyTypes | None=None, follow_redirects:bool=False, verify:ssl.SSLContext | str | bool=True,\n    timeout:TimeoutTypes=Timeout(timeout=5.0), trust_env:bool=True\n):\n\nRead text from url and clean with clean_docs\n\nmdurl = 'https://claudette.answer.ai/index.html.md'\nmd = read_md(mdurl)\n# Markdown(md)\n\n\nsource\n\n\nhtml2md\n\ndef html2md(\n    s:str, ignore_links:bool=True\n):\n\nConvert s from HTML to markdown\n\nsource\n\n\nread_html\n\ndef read_html(\n    url, # URL to read\n    sel:NoneType=None, # Read only outerHTML of CSS selector `sel`\n    rm_comments:bool=True, # Removes HTML comments\n    rm_details:bool=True, # Removes `&lt;details&gt;` tags\n    multi:bool=False, # Get all matches to `sel` or first one\n    wrap_tag:NoneType=None, # If multi, each selection wrapped with &lt;wrap_tag&gt;content&lt;/wrap_tag&gt;\n    ignore_links:bool=True\n):\n\nGet url, optionally selecting CSS selector sel, and convert to clean markdown\n\n# test single class selector\nlistings = read_html('https://www.answer.ai/', sel='.listing-description')\nassert len(listings) &lt; 500\n\n# Test multi class selector\nlistings = read_html('https://www.answer.ai/', sel='.listing-description', multi=True)\nassert len(listings) &gt; 1000 # returns more than single so selecting multi\n\n# Test multi_wrap_tag\nlistings = read_html('https://www.answer.ai/', sel='.listing-description', multi=True, wrap_tag='document')\nassert '&lt;document&gt;' in listings and '&lt;/document&gt;' in listings\n\n\nread_html('https://www.answer.ai/', sel='.listing-description', ignore_links=False)\n\n'[ How I created a book chapter from video transcripts with SolveIt ](./posts/2025-10-13-video-to-doc.html)\\n\\n'\n\n\n\n# test tag css selectors\nassert len(read_html('https://www.answer.ai/', sel='div.listing-description', multi=True)) &gt; 1000\nassert len(read_html('https://www.answer.ai/', sel='div', multi=True)) &gt; 1000\n\n\nhtmlurl = 'https://hypermedia.systems/hypermedia-a-reintroduction/'\nhmd = read_html(htmlurl)\nassert len(hmd) &gt; 100\n# Markdown(hmd)\n\n\nsource\n\n\nget_llmstxt\n\ndef get_llmstxt(\n    url, optional:bool=False, n_workers:NoneType=None\n):\n\nGet llms.txt file from and expand it with llms_txt.create_ctx()\n\n# print(get_llmstxt('https://llmstxt.org/llms.txt'))\n\n\nsource\n\n\nsplit_url\n\ndef split_url(\n    url\n):\n\nSplit url into base, path, and file name, normalising name to ‘/’ if empty\n\nurls = ('https://claudette.answer.ai/path/', 'https://claudette.answer.ai/', 'https://llmstxt.org', 'https://llmstxt.org/')\n\n[split_url(o) for o in urls]\n\n[('https://claudette.answer.ai', '', '/path'),\n ('https://claudette.answer.ai', '/', ''),\n ('https://llmstxt.org', '/', ''),\n ('https://llmstxt.org', '/', '')]\n\n\n\nsource\n\n\nfind_docs\n\ndef find_docs(\n    url\n):\n\nIf available, return LLM-friendly llms.txt context or markdown file location from url\n\nfl_url = 'https://answerdotai.github.io/fastlite'\n\n\nfind_docs(fl_url)\n\n'https://answerdotai.github.io/fastlite/llms.txt'\n\n\n\nfor o in urls: print(find_docs(o))\n\nhttps://claudette.answer.ai/llms.txt\nhttps://claudette.answer.ai/llms.txt\nhttps://llmstxt.org/llms.txt\nhttps://llmstxt.org/llms.txt\n\n\n\nsuffixes = [\"/\", \"/tmp\", \"/tmp/tmp/\"]\nfor suff in suffixes:\n    for o in urls:  test_eq(find_docs(o), find_docs(o+suff))\n\ntest_eq(find_docs(\"https://github.com\"), \"https://github.com/llms.txt\")\ntest_eq(find_docs(\"https://github.com/AnswerDotAI\"), \"https://github.com/llms.txt\")\ntest_eq(find_docs(\"https://github.com/AnswerDotAI/\"), \"https://github.com/llms.txt\")\n\n\nsource\n\n\nread_docs\n\ndef read_docs(\n    url, optional:bool=False, n_workers:NoneType=None, rm_comments:bool=True, rm_details:bool=True\n):\n\nIf available, return LLM-friendly llms.txt context or markdown file response for url",
    "crumbs": [
      "Download helpers"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "toolslm",
    "section": "",
    "text": "This is a work in progress…",
    "crumbs": [
      "toolslm"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "toolslm",
    "section": "Install",
    "text": "Install\npip install toolslm",
    "crumbs": [
      "toolslm"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "toolslm",
    "section": "How to use",
    "text": "How to use\n\nContext creation\ntoolslm has some helpers to make it easier to generate XML context from files, for instance folder2ctx:\n\nprint(folder2ctx('samples', prefix=False, file_glob='*.py'))\n\n&lt;documents&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\nsamples/sample_core.py\n&lt;/src&gt;&lt;document-content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n&lt;/document-content&gt;&lt;/document&gt;&lt;/documents&gt;\n\n\nJSON doesn’t map as nicely to XML as the ft data structure from fastcore.xml, but for simple XML trees it can be convenient. The json_to_xml function handles that conversion:\n\na = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n         address=dict(state='Queensland',country='Australia'))\nprint(json_to_xml(a, 'person'))\n\n&lt;person&gt;\n  &lt;surname&gt;Howard&lt;/surname&gt;\n  &lt;firstnames&gt;\n    &lt;item&gt;Jeremy&lt;/item&gt;\n    &lt;item&gt;Peter&lt;/item&gt;\n  &lt;/firstnames&gt;\n  &lt;address&gt;\n    &lt;state&gt;Queensland&lt;/state&gt;\n    &lt;country&gt;Australia&lt;/country&gt;\n  &lt;/address&gt;\n&lt;/person&gt;",
    "crumbs": [
      "toolslm"
    ]
  },
  {
    "objectID": "inspecttools.html",
    "href": "inspecttools.html",
    "title": "inspecttools",
    "section": "",
    "text": "This module provides LLM tools to dynamically inspect source code, types, and module capabilities. Functions take string arguments (dotted symbol paths) rather than Python objects because LLM tool interfaces can only pass serializable values—not live Python references.\nfrom IPython.display import display,Markdown\nimport textwrap",
    "crumbs": [
      "inspecttools"
    ]
  },
  {
    "objectID": "inspecttools.html#helpers",
    "href": "inspecttools.html#helpers",
    "title": "inspecttools",
    "section": "Helpers",
    "text": "Helpers\n\nsource\n\nimportmodule\n\ndef importmodule(\n    mod:str, # The module to import (e.g. 'torch.nn.functional')\n    caller_symbol:str='__dialog_name', # The name of the special variable to find the correct caller namespace\n):\n\nImport a module into the caller’s global namespace so it’s available for symsrc, symval, symdir, etc. Use this before inspecting or using symbols from modules not yet imported.\nimportmodule lets the LLM dynamically import modules by name. Here we import fastcore.utils and verify it’s available.\n\nimportmodule('fastcore.utils')\nfastcore.__version__\n\n'1.12.5'\n\n\n\nsource\n\n\nresolve\n\ndef resolve(\n    sym:str, # Dotted symbol path, with optional [n] indexing, e.g. \"module.attr.subattr[1]\" or \"_last\" for previous result\n):\n\nResolve a dotted symbol string to its Python object, with optional [n] indexing. Sets global _last to the resolved object for chaining. Pass \"_last\" to reference the result of the previous tool call.\nExamples:\n\nresolve(\"sympy.sets.sets.Interval\") -&gt; &lt;class 'sympy.sets.sets.Interval'&gt;\nresolve(\"mylist[2]\") -&gt; third element of mylist\n\n\nsource\n\n\nSymbolNotFound\n\ndef SymbolNotFound(\n    args:VAR_POSITIONAL, kwargs:VAR_KEYWORD\n):\n\nCommon base class for all non-exit exceptions.\nresolve navigates dotted paths like \"a.argfirst\" to reach the actual Python object.\n\na = fastcore.utils.L(1)\nresolve('a.argfirst')\n\n&lt;bound method L.argfirst of [1]&gt;\n\n\nIt also sets _last for chaining. Since it’s used internally by all get* tools in this module, the tools all set _last too.\n\n_last\n\n&lt;bound method L.argfirst of [1]&gt;\n\n\nIt works on both objects and classes:\n\nresolve('fastcore.utils.L.argfirst')\n\n&lt;function fastcore.foundation.L.argfirst(self: fastcore.foundation.L, f, negate=False)&gt;",
    "crumbs": [
      "inspecttools"
    ]
  },
  {
    "objectID": "inspecttools.html#symbol-info",
    "href": "inspecttools.html#symbol-info",
    "title": "inspecttools",
    "section": "Symbol info",
    "text": "Symbol info\n\nsource\n\nsymsrc\n\ndef symsrc(\n    sym:str, # Dotted symbol path (e.g `Interval` or `sympy.sets.sets.Interval`) or \"_last\" for previous result\n):\n\nGet the source code for a symbol.\nExamples:\n\nsymsrc(\"Interval\") -&gt; source code of Interval class if it’s already imported\nsymsrc(\"sympy.sets.sets.Interval\") -&gt; source code of Interval class\nsymsrc(\"_last\") -&gt; source of object from previous tool call\nFor dispatchers or registries of callables: symnth(\"module.dispatcher.funcs\", n) then symsrc(\"_last\")\n\nsymsrc retrieves the source code of any symbol by path—essential for letting the LLM understand how functions work.\n\nprint(symsrc('a.argfirst'))\n\nFile: /Users/jhoward/aai-ws/fastcore/fastcore/foundation.py\n\n@patch\n@curryable\ndef argfirst(self:L, f, negate=False):\n    \"Return index of first matching item\"\n    if negate: f = not_(f)\n    return first(i for i,o in self.enumerate() if f(o))\n\n\n\n\nclass B:\n    def a(): ...\nb = B()\nprint(symsrc('b'))\n\nFile: /var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_33003/2711726673.py\n\nclass B:\n    def a(): ...\n\n\n\n\ndef f():\n    \"testing\"\n    return 1\nprint(symsrc('f'))\n\nFile: /var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_33003/242320393.py\n\ndef f():\n    \"testing\"\n    return 1\n\n\n\n\nfrom toolslm import xml\n\n\nprint(symsrc('xml')[:200])\n\nFile: /Users/jhoward/aai-ws/toolslm/toolslm/xml.py\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_xml.ipynb.\n\n# %% auto #0\n__all__ = ['doctype', 'json_to_xml', 'get_mime_text', 'cell2out', 'cell2x\n\n\n\nsource\n\n\nsymtype\n\ndef symtype(\n    syms:str, # Comma separated str list of dotted symbol paths (e.g `'Interval,a'` or `'sympy.sets.sets.Interval'`); \"_last\" for prev result\n):\n\nGet the type of a symbol and set _last.\nExamples:\n\nsymtype(\"sympy.sets.sets.Interval\") -&gt; &lt;class 'type'&gt;\nsymtype(\"doesnotexist\") -&gt; 'SymbolNotFound\nsymtype(\"_last\") -&gt; type of previous result\n\nsymtype returns the type of a symbol—useful for the LLM to understand what kind of object it’s dealing with.\n\nsymtype('a.argfirst')\n\n[method]\n\n\n\nsymtype('fffaa,b')\n\n[\"SymbolNotFound(Symbol 'fffaa' not found. Consider using `importmodule` first.)\",\n __main__.B]\n\n\n\nsource\n\n\nsymval\n\ndef symval(\n    syms:str, # Comma separated str list of dotted symbol paths (e.g `Interval` or `sympy.sets.sets.Interval`); \"_last\" for prev result\n):\n\nList of repr of symbols’ values.\nExamples:\n\nsymval(\"sympy.sets.sets.Interval\") -&gt; [&lt;class 'sympy.sets.sets.Interval'&gt;]\nsymval(\"some_dict.keys\") -&gt; [dict_keys([...])]\nsymval(\"a,notexist\") -&gt; ['foo','SymbolNotFound']\n\nsymval returns the repr() of a symbol’s value—handy for inspecting data without needing to execute arbitrary code.\n\na\n\n[1]\n\n\n\nsymval('a,foofoo')\n\n['[1]',\n \"SymbolNotFound(Symbol 'foofoo' not found. Consider using `importmodule` first.)\"]\n\n\n\nsource\n\n\nsymtype_val\n\ndef symtype_val(\n    syms:str, # Comma separated str list of dotted symbol paths (e.g `Interval` or `sympy.sets.sets.Interval`); \"_last\" for prev result\n):\n\nList of 2-ple of (type,repr) of symbols’ values.\nExamples:\n\nsymtype_val(\"a,c,notexist\") -&gt; [(&lt;class 'str'&gt;,'foo'),(&lt;class 'int'&gt;,1), 'SymbolNotFound']\n\n\nsymtype_val('a,b,foofoo')\n\n[(fastcore.foundation.L, '[1]'),\n (__main__.B, '&lt;__main__.B object&gt;'),\n 'SymbolNotFound']\n\n\n\nsource\n\n\nsymdir\n\ndef symdir(\n    sym:str, # Dotted symbol path (e.g `Interval` or `sympy.sets.sets.Interval`) or \"_last\" for previous result\n    exclude_private:bool=False, # Filter out attrs starting with \"_\"\n):\n\nGet dir() listing of a symbol’s attributes and set _last. E.g: symdir(\"sympy.Interval\") -&gt; ['__add__', '__and__', ...]\nsymdir lists all attributes of an object (i.e it calls dir(). Here we filter out private names to see the public API of an L list.\n\n' '.join(symdir('a', exclude_private=True))\n\n'accumulate append argfirst argwhere attrgot batched clear combinations compress concat copy copy count cycle dropwhile enumerate extend filter flatmap flatten groupby index insert itemgot items map map_dict map_first map_zip map_zipwith pairwise partition permutations pop product range reduce remove renumerate reverse rstarargfirst rstarargwhere rstardropwhile rstarfilter rstarmap rstarpartition rstarreduce rstarsorted rstartakewhile setattrs shuffle sort sorted split splitlines starargfirst starargwhere stardropwhile starfilter starmap starpartition starreduce starsorted startakewhile sum takewhile unique val2idx zip zipwith'\n\n\n\nsource\n\n\nsymnth\n\ndef symnth(\n    sym:str, # Dotted symbol path to a dict or object with .values()\n    n:int, # Index into the values (0-based)\n):\n\nGet the nth value from a dict (or any object with .values()). Sets _last so you can chain with symsrc(\"_last\") etc.\nExamples:\n\nsymnth(\"dispatcher.funcs\", 12) -&gt; 13th registered function\nsymnth(\"dispatcher.funcs\", 0); symsrc(\"_last\") -&gt; source of first handler\n\nsymnth extracts the nth value from a dict (or anything with .values()).\n\nhandlers = dict(int=lambda x: x*2, str=lambda x: x.upper(), list=lambda x: len(x))\nsymnth('handlers', 0)\n\n&lt;function __main__.&lt;lambda&gt;(x)&gt;\n\n\nCombined with _last, this lets the LLM drill into registries of handlers/dispatchers and then inspect their source.\n\nsymsrc('_last')\n\n'File: /var/folders/51/b2_szf2945n072c0vj2cyty40000gn/T/ipykernel_33003/340145363.py\\n\\nhandlers = dict(int=lambda x: x*2, str=lambda x: x.upper(), list=lambda x: len(x))\\n'\n\n\n\nsource\n\n\nsymlen\n\ndef symlen(\n    sym:str, # Dotted symbol path or \"_last\" for previous result\n):\n\nReturns the length of the given symbol\n\nsource\n\n\nsymslice\n\ndef symslice(\n    sym:str, # Dotted symbol path or \"_last\" for previous result\n    start:int, # Starting index for slice\n    end:int, # Ending index for slice\n):\n\nReturns the contents of the symbol from the given start to the end.\n\na = ['a', 'b', 'c', 'd']\nsymslice('a', 1, 3)\n\n['b', 'c']\n\n\nOn failure we get a str error:\n\nsymslice('resolve', 0, 1)\n\n\"Error: 'function' object is not subscriptable\"\n\n\n\nsource\n\n\nsymsearch\n\ndef symsearch(\n    sym:str, # Dotted symbol path or \"_last\" for previous result\n    term:str, # Search term (exact string or regex pattern)\n    regex:bool=True, # If True, regex search; if False, exact match\n    flags:int=0, # Regex flags (e.g., re.IGNORECASE)\n):\n\nSearch contents of symbol, which is assumed to be str for regex, or iterable for non-regex. Regex mode returns (match, start, end) tuples; otherwise returns (item, index) tuples\n\nsymsearch('a', 'c', regex=False), symsearch('a', 'z', regex=False)\n\n(\"[('c', 2)]\", '[]')\n\n\n\ntext = \"The quick brown fox jumps over 3 lazy dogs and 12 cats\"\n\n\nsymsearch('text', r'\\d+', regex=True)\n\n\"[('3', 31, 32), ('12', 47, 49)]\"\n\n\n\nsymsearch('text', r'\\b[aeiou]\\w*', regex=True, flags=re.IGNORECASE)\n\n\"[('over', 26, 30), ('and', 43, 46)]\"\n\n\n\nsource\n\n\nsymset\n\ndef symset(\n    val:str, # Value to assign to _ai_sym\n):\n\n*Set _ai_sym to the given value*\n\nsymset('Otters are awesome!'); _ai_sym\n\n'Otters are awesome!'",
    "crumbs": [
      "inspecttools"
    ]
  },
  {
    "objectID": "inspecttools.html#symbol-context",
    "href": "inspecttools.html#symbol-context",
    "title": "inspecttools",
    "section": "Symbol context",
    "text": "Symbol context\n\nsource\n\nsymfiles_folder\n\ndef symfiles_folder(\n    sym:str, # Dotted symbol path or \"_last\" for previous result\n    types:str | list='py', # List or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    skip_file_re:str='^_mod', # Skip files matching regex\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_folder_re:str=None, # Skip folders matching regex,\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    exts:str | list=None, # list or comma-separated str of exts to include\n):\n\nReturn XML context of files in the folder containing sym’s definition\n\n# print(symfiles_folder('xml'))\n\n\nsource\n\n\nsymfiles_package\n\ndef symfiles_package(\n    sym:str, # Dotted symbol path or \"_last\" for previous result\n    types:str | list='py', # List or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    skip_file_re:str='^_mod', # Skip files matching regex\n    skip_folder_re:str='^(\\\\.|__)', # Skip folders matching regex\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    exts:str | list=None, # list or comma-separated str of exts to include\n):\n\nReturn XML context of all files in sym’s top-level package\n\n# print(symfiles_package('xml'))",
    "crumbs": [
      "inspecttools"
    ]
  },
  {
    "objectID": "shell.html",
    "href": "shell.html",
    "title": "shell source",
    "section": "",
    "text": "Exported source\nimport ast, time, signal, traceback\nfrom fastcore.utils import *\n\n\nget_shell is like python, except it also maintains a stateful interpreter, rather than just running a single line of code. This is implemented using IPython, so that must be installed.\n\n\nExported source\nfrom IPython.terminal.interactiveshell import TerminalInteractiveShell\nfrom IPython.utils.capture import capture_output\n\n\n\ndef exception2str(ex:Exception)-&gt;str:\n    \"Convert exception `ex` into a string\"\n    return ''.join(traceback.format_exception(type(ex), ex, ex.__traceback__))\n\n\ntry: print(1/0)\nexcept Exception as e: print(exception2str(e))\n\nTraceback (most recent call last):\n  File \"/var/folders/ss/34z569j921v58v8n1n_8z7h40000gn/T/ipykernel_37260/4058275565.py\", line 1, in &lt;module&gt;\n    try: print(1/0)\n               ~^~\nZeroDivisionError: division by zero\n\n\n\n\nsource\n\nTerminalInteractiveShell.run_cell\n\ndef run_cell(\n    cell, timeout:NoneType=None\n):\n\nWrapper for original run_cell which adds timeout and output capture\n\n\nExported source\nTerminalInteractiveShell.orig_run = TerminalInteractiveShell.run_cell\n\n\n\n\nExported source\n@patch\ndef run_cell(self:TerminalInteractiveShell, cell, timeout=None):\n    \"Wrapper for original `run_cell` which adds timeout and output capture\"\n    if timeout:\n        def handler(*args): raise TimeoutError()\n        signal.signal(signal.SIGALRM, handler)\n        signal.alarm(timeout)\n    try:\n        with capture_output() as io: result = self.orig_run(cell)\n        result.stdout = io.stdout\n        return result\n    except TimeoutException as e:\n        result = self.ExecutionResult(error_before_exec=None, error_in_exec=e)\n    finally:\n        if timeout: signal.alarm(0)\n\n\n\nsource\n\n\nget_shell\n\ndef get_shell(\n    \n)-&gt;TerminalInteractiveShell:\n\nGet a TerminalInteractiveShell with minimal functionality\n\n\nExported source\ndef get_shell()-&gt;TerminalInteractiveShell:\n    \"Get a `TerminalInteractiveShell` with minimal functionality\"\n    sh = TerminalInteractiveShell()\n    sh.logger.log_output = sh.history_manager.enabled = False\n    dh = sh.displayhook\n    dh.finish_displayhook = dh.write_output_prompt = dh.start_displayhook = lambda: None\n    dh.write_format_data = lambda format_dict, md_dict=None: None\n    sh.logstart = sh.automagic = sh.autoindent = False\n    sh.autocall = 0\n    sh.system = lambda cmd: None\n    return sh\n\n\n\nshell = get_shell()\n\n\nr = shell.run_cell('print(3); 1+1')\nr.result,r.stdout\n\n(2, '3\\n')\n\n\n\nr = shell.run_cell('raise Exception(\"blah\")')\nprint(exception2str(r.error_in_exec))\n\nTraceback (most recent call last):\n  File \"/Users/jhoward/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"&lt;ipython-input-1-338156281413&gt;\", line 1, in &lt;module&gt;\n    raise Exception(\"blah\")\nException: blah\n\n\n\n\nr = shell.run_cell('import time; time.sleep(10)', timeout=1)\nr.error_in_exec\n\nTimeoutError()",
    "crumbs": [
      "shell source"
    ]
  },
  {
    "objectID": "xml.html",
    "href": "xml.html",
    "title": "xml source",
    "section": "",
    "text": "from copy import deepcopy\n\nfrom fastcore.test import *",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#json-to-xml",
    "href": "xml.html#json-to-xml",
    "title": "xml source",
    "section": "JSON to XML",
    "text": "JSON to XML\n\nsource\n\njson_to_xml\n\ndef json_to_xml(\n    d:dict, # JSON dictionary to convert\n    rnm:str, # Root name\n)-&gt;str:\n\nConvert d to XML.\nJSON doesn’t map as nicely to XML as the data structure used in fastcore.xml, but for simple XML trees it can be convenient – for example:\n\na = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n         address=dict(state='Queensland',country='Australia'))\nhl_md(json_to_xml(a, 'person'))\n\n&lt;person&gt;\n  &lt;surname&gt;Howard&lt;/surname&gt;\n  &lt;firstnames&gt;\n    &lt;item&gt;Jeremy&lt;/item&gt;\n    &lt;item&gt;Peter&lt;/item&gt;\n  &lt;/firstnames&gt;\n  &lt;address&gt;\n    &lt;state&gt;Queensland&lt;/state&gt;\n    &lt;country&gt;Australia&lt;/country&gt;\n  &lt;/address&gt;\n&lt;/person&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#including-documents",
    "href": "xml.html#including-documents",
    "title": "xml source",
    "section": "Including documents",
    "text": "Including documents\n\nNotebooks\n\nnbp = Path('00_xml.ipynb')\nnb = dict2obj(nbp.read_json())\ncells = nb.cells\ncell = cells[7]\ncell\n\n{ 'cell_type': 'code',\n  'execution_count': {},\n  'id': '005a5be4',\n  'metadata': {},\n  'outputs': [],\n  'source': [\"a = dict(surname='Howard', firstnames=['Jeremy','Peter'],\\n\", \"         address=dict(state='Queensland',country='Australia'))\\n\", \"hl_md(json_to_xml(a, 'person'))\"]}\n\n\n\nsource\n\n\nget_mime_text\n\ndef get_mime_text(\n    data\n):\n\nGet text from MIME bundle, preferring markdown over plain\n\nsource\n\n\ncell2out\n\ndef cell2out(\n    o\n):\n\nConvert single notebook output to XML format\n\nfor o in cell.outputs: print(to_xml(cell2out(o), do_escape=False))\n\n\nsource\n\n\ncell2xml\n\ndef cell2xml(\n    cell, out:bool=True, ids:bool=True, nums:bool=False\n):\n\nConvert notebook cell to concise XML format\n\nhl_md(cell2xml(cell, out=False, nums=True))\n\n&lt;code id=\"005a5be4\"&gt;     1 │ a = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n     2 │          address=dict(state='Queensland',country='Australia'))\n     3 │ hl_md(json_to_xml(a, 'person'))&lt;/code&gt;\n\n\n\nsource\n\n\nnb2xml\n\ndef nb2xml(\n    fname:NoneType=None, nb:NoneType=None, out:bool=True, ids:bool=True, nums:bool=False\n):\n\nConvert notebook to XML format\n\nsource\n\n\ncells2xml\n\ndef cells2xml(\n    cells, wrap:function=_f, out:bool=True, ids:bool=True, nums:bool=False\n):\n\nConvert notebook to XML format\n\nnbsml = deepcopy(nb)\ndel(nbsml.cells[2:])\n\nhl_md(nb2xml(nb=nbsml))\n\n&lt;notebook&gt;&lt;code id=\"efe78920\"&gt;&lt;source&gt;#|default_exp xml&lt;/code&gt;&lt;md id=\"87ea05a3\"&gt;&lt;source&gt;# xml source&lt;/md&gt;&lt;/notebook&gt;\n\n\n\nhl_md(nb2xml(nb=nbsml, ids=False))\n\n&lt;notebook&gt;&lt;code&gt;&lt;source&gt;#|default_exp xml&lt;/code&gt;&lt;md&gt;&lt;source&gt;# xml source&lt;/md&gt;&lt;/notebook&gt;\n\n\n\n\nDocuments\nAccording to Anthropic, “it’s essential to structure your prompts in a way that clearly separates the input data from the instructions”. They recommend using something like the following:\nHere are some documents for you to reference for your task:\n    \n&lt;documents&gt;\n&lt;document index=\"1\"&gt;\n&lt;source&gt;\n(URL, file name, hash, etc)\n&lt;/source&gt;\n&lt;document_content&gt;\n(the text content)\n&lt;/document_content&gt;\n&lt;/document&gt;\n&lt;/documents&gt;\nWe will create some small helper functions to make it easier to generate context in this format, although we’re use &lt;src&gt; instead of &lt;source&gt; to avoid conflict with that HTML tag. Although it’s based on Anthropic’s recommendation, it’s likely to work well with other models too.\nWe’ll use doctype to store our pairs.\nSince Anthropic’s example shows newlines before and after each tag, we’ll do the same.\n\nto_xml(Src('a'))\n\n'&lt;src&gt;a&lt;/src&gt;'\n\n\n\nto_xml(Document('a'))\n\n'&lt;document&gt;a&lt;/document&gt;'\n\n\n\nsource\n\n\nmk_doctype\n\ndef mk_doctype(\n    content:str, # The document content\n    src:Optional=None, # URL, filename, etc; defaults to `md5(content)` if not provided\n)-&gt;namedtuple:\n\nCreate a doctype named tuple\nThis is a convenience wrapper to ensure that a doctype has the needed information in the right format.\n\ndoc = 'This is a \"sample\"'\nmk_doctype(doc)\n\ndoctype(src='\\n47e19350\\n', content='\\nThis is a \"sample\"\\n')\n\n\n\nsource\n\n\nmk_doc\n\ndef mk_doc(\n    index:int, # The document index\n    content:str, # The document content\n    src:Optional=None, # URL, filename, etc; defaults to `md5(content)` if not provided\n    kwargs:VAR_KEYWORD\n)-&gt;tuple:\n\nCreate an ft format tuple for a single doc in Anthropic’s recommended format\nWe can now generate XML for one document in the suggested format:\n\nmk_doc(1, doc, title=\"test\")\n\n\n47e19350\n\nThis is a \"sample\"\n\n\n\n\nsource\n\n\ndocs_xml\n\ndef docs_xml(\n    docs:list, # The content of each document\n    srcs:Optional=None, # URLs, filenames, etc; each one defaults to `md5(content)` if not provided\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    details:Optional=None, # Optional list of dicts with additional attrs for each doc\n    title:str=None, # Optional title attr for Documents element\n)-&gt;str:\n\nCreate an XML string containing docs in Anthropic’s recommended format\nPutting it all together, we have our final XML format:\n\ndocs = [doc, 'And another one']\nsrcs = [None, 'doc.txt']\nprint(docs_xml(docs, srcs))\n\n&lt;documents&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\n47e19350\n&lt;/src&gt;&lt;document-content&gt;\nThis is a \"sample\"\n&lt;/document-content&gt;&lt;/document&gt;&lt;document index=\"2\"&gt;&lt;src&gt;\ndoc.txt\n&lt;/src&gt;&lt;document-content&gt;\nAnd another one\n&lt;/document-content&gt;&lt;/document&gt;&lt;/documents&gt;",
    "crumbs": [
      "xml source"
    ]
  },
  {
    "objectID": "xml.html#context-creation",
    "href": "xml.html#context-creation",
    "title": "xml source",
    "section": "Context creation",
    "text": "Context creation\nNow that we can generate Anthropic’s XML format, let’s make it easy for a few common cases.\n\nFile list to context\nFor generating XML context from files, we’ll just read them as text and use the file names as src.\n\nsource\n\n\nread_file\n\ndef read_file(\n    fname, max_size:NoneType=None, sigs_only:bool=False, nb:NoneType=None, out:bool=True, ids:bool=True,\n    nums:bool=False\n):\n\nRead file content, converting notebooks to XML if needed\n\nsource\n\n\nfiles2ctx\n\ndef files2ctx(\n    fnames:list, # List of file names to add to context\n    srcs:Optional=None, # Use the labels instead of `fnames`\n    max_size:int=None, # Skip files larger than this (bytes)\n    out:bool=True, # Include notebook cell outputs?\n    ids:bool=True, # Include cell ids in notebooks?\n    nums:bool=False, # Include line numbers in notebook cell source?\n    sigs_only:bool=False, # Only include signatures and docstrings (where supported by `codesigs` lib)\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    details:Optional=None, # Optional list of dicts with additional attrs for each doc\n    title:str=None, # Optional title attr for Documents element\n)-&gt;str: # XML for LM context\n\nConvert files to XML context, handling notebooks\n\nfnames = ['samples/sample_core.py', 'samples/sample_styles.css']\nhl_md(files2ctx(fnames, max_size=120))\n\n&lt;documents&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\nsamples/sample_core.py\n&lt;/src&gt;&lt;document-content&gt;\n[Skipped: sample_core.py exceeds 120 bytes]\n&lt;/document-content&gt;&lt;/document&gt;&lt;document index=\"2\"&gt;&lt;src&gt;\nsamples/sample_styles.css\n&lt;/src&gt;&lt;document-content&gt;\n.cell { margin-bottom: 1rem; }\n.cell &gt; .sourceCode { margin-bottom: 0; }\n.cell-output &gt; pre { margin-bottom: 0; }\n&lt;/document-content&gt;&lt;/document&gt;&lt;/documents&gt;\n\n\n\n\nFolder to context\n\nsource\n\n\nfolder2ctx\n\ndef folder2ctx(\n    path:Union, # Folder to read\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_file_re:str=None, # Skip files matching regex\n    skip_folder_re:str=None, # Skip folders matching regex,\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    types:str | list=None, # list or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    exts:str | list=None, # list or comma-separated str of exts to include\n)-&gt;Union:\n\nConvert folder contents to XML context, handling notebooks\n\nprint(folder2ctx('samples', prefix=True, types='py'))\n\nHere are some documents for you to reference for your task:\n\n&lt;documents&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\nsamples/sample_core.py\n&lt;/src&gt;&lt;document-content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n&lt;/document-content&gt;&lt;/document&gt;&lt;/documents&gt;\n\n\n\nsource\n\n\nsym2file\n\ndef sym2file(\n    sym\n):\n\nReturn md string with filepath and contents for a symbol’s source file\n\n# print(sym2file(Path))\n\n\nsource\n\n\nsym2folderctx\n\ndef sym2folderctx(\n    sym,\n    types:str | list='py', # List or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    skip_file_re:str='^_mod', # Skip files matching regex\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_folder_re:str=None, # Skip folders matching regex,\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    exts:str | list=None, # list or comma-separated str of exts to include\n):\n\nReturn folder context for a symbol’s source file location\n\n# print(sym2folderctx(test_eq))\n\n\nsource\n\n\nsym2pkgpath\n\ndef sym2pkgpath(\n    sym\n):\n\nGet root package path for a symbol\n\nsym2pkgpath(test_eq)\n\nPath('/Users/jhoward/aai-ws/fastcore/fastcore')\n\n\n\nsource\n\n\nsym2pkgctx\n\ndef sym2pkgctx(\n    sym,\n    types:str | list='py', # List or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    skip_file_re:str='^_mod', # Skip files matching regex\n    skip_folder_re:str='^(\\\\.|__)', # Skip folders matching regex\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    exts:str | list=None, # list or comma-separated str of exts to include\n):\n\nReturn contents of files in a symbol’s root package\n\n# print(sym2pkgctx(test_eq))\n\n\n\n\n\n\n\nTip\n\n\n\nAfter you install toolslm, folder2ctx becomes available from the command line.\n\n\n\n!folder2ctx -h\n\nusage: folder2ctx [-h] [--path PATH] [--no-out] [--prefix] [--no-include_base]\n                  [--title TITLE] [--max_size MAX_SIZE] [--max_total MAX_TOTAL]\n                  [--readme_first] [--files_only] [--sigs_only] [--no-ids]\n                  [--no-recursive] [--no-symlinks] [--file_glob FILE_GLOB]\n                  [--file_re FILE_RE] [--folder_re FOLDER_RE]\n                  [--skip_file_glob SKIP_FILE_GLOB]\n                  [--skip_file_re SKIP_FILE_RE]\n                  [--skip_folder_re SKIP_FOLDER_RE] [--ret_folders] [--no-sort]\n                  [--types TYPES] [--exts EXTS]\n\nCLI to convert folder contents to XML context, handling notebooks\n\noptions:\n  -h, --help                       show this help message and exit\n  --path PATH                      Folder name containing files to add to\n                                   context (default: .)\n  --no-out                         Include notebook cell outputs? (default:\n                                   True)\n  --prefix                         Include Anthropic's suggested prose intro?\n                                   (default: False)\n  --no-include_base                Include full path in src? (default: True)\n  --title TITLE                    Optional title attr for Documents element\n  --max_size MAX_SIZE              Skip files larger than this (bytes) (default:\n                                   100000)\n  --max_total MAX_TOTAL            Max total output size in bytes (default:\n                                   10000000)\n  --readme_first                   Prioritize README files at start of context?\n                                   (default: False)\n  --files_only                     Return dict of {filename: size} instead of\n                                   context? (default: False)\n  --sigs_only                      Return signatures instead of full text for\n                                   python files? (default: False)\n  --no-ids                         Include cell ids in notebooks? (default:\n                                   True)\n  --no-recursive                   search subfolders (default: True)\n  --no-symlinks                    follow symlinks? (default: True)\n  --file_glob FILE_GLOB            Only include files matching glob\n  --file_re FILE_RE                Only include files matching regex\n  --folder_re FOLDER_RE            Only enter folders matching regex\n  --skip_file_glob SKIP_FILE_GLOB  Skip files matching glob\n  --skip_file_re SKIP_FILE_RE      Skip files matching regex\n  --skip_folder_re SKIP_FOLDER_RE  Skip folders matching regex,\n  --ret_folders                    return folders, not just files (default:\n                                   False)\n  --no-sort                        sort files by name within each folder\n                                   (default: True)\n  --types TYPES                    list or comma-separated str of ext types\n                                   from: py, js, java, c, cpp, rb, r, ex, sh,\n                                   web, doc, cfg\n  --exts EXTS                      list or comma-separated str of exts to\n                                   include\n\n\n\nsource\n\n\nparse_gh_url\n\ndef parse_gh_url(\n    url\n):\n\nParse GitHub URL into (owner, repo, type, ref, path) or None\n\nsource\n\n\nrepo2ctx\n\ndef repo2ctx(\n    owner:str, # GitHub repo owner or \"owner/repo\" or a full github URL\n    repo:str=None, # GitHub repo name (leave empty if using \"owner/repo\" or URL format for owner param)\n    ref:str=None, # Git ref (branch/tag/sha) (get from URL not provided); defaults to repo's default branch\n    folder:str=None, # Only include files under this path (get from URL not provided)\n    show_filters:bool=True, # Include filter info in title?\n    token:str=None, # GitHub token (uses GITHUB_TOKEN env var if None)\n    prefix:bool=False, # Include Anthropic's suggested prose intro?\n    out:bool=True, # Include notebook cell outputs?\n    include_base:bool=True, # Include full path in src?\n    title:str=None, # Optional title attr for Documents element\n    max_size:int=100000, # Skip files larger than this (bytes)\n    max_total:int=10000000, # Max total output size in bytes\n    readme_first:bool=False, # Prioritize README files at start of context?\n    files_only:bool=False, # Return dict of {filename: size} instead of context?\n    sigs_only:bool=False, # Return signatures instead of full text? (where supported by `codesigs` lib)\n    ids:bool=True, # Include cell ids in notebooks?\n    recursive:bool=True, # search subfolders\n    symlinks:bool=True, # follow symlinks?\n    file_glob:str=None, # Only include files matching glob\n    file_re:str=None, # Only include files matching regex\n    folder_re:str=None, # Only enter folders matching regex\n    skip_file_glob:str=None, # Skip files matching glob\n    skip_file_re:str=None, # Skip files matching regex\n    skip_folder_re:str=None, # Skip folders matching regex,\n    ret_folders:bool=False, # return folders, not just files\n    sort:bool=True, # sort files by name within each folder\n    types:str | list=None, # list or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg\n    exts:str | list=None, # list or comma-separated str of exts to include\n)-&gt;Union: # XML for LM context, or dict of file sizes\n\nConvert GitHub repo to XML context without cloning\n\nprint(repo2ctx('answerdotai/toolslm', exts=('ipynb','py'), skip_file_re='^_', out=False, max_total=500))\n\n&lt;documents title=\"GitHub repository contents from answerdotai/toolslm/main (filters applied -- exts: ipynb, py | skip_file_re: ^_ | max_total: 500)\"&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\n00_xml.ipynb\n&lt;/src&gt;&lt;document-content&gt;\n&lt;notebook&gt;&lt;code id=\"efe78920\"&gt;#|default_exp xml&lt;/code&gt;&lt;md id=\"87ea05a3\"&gt;# xml source&lt;/md&gt;&lt;code id=\"033c76fd\"&gt;#| export\nimport hashlib, inspect, xml.etree.ElementTree as ET, ast\nfrom collections import namedtuple\nfrom ghapi.all\n\n[TRUNCATED: output size 106522 exceeded max size 500 bytes]\n\n\n\nprint(repo2ctx('answerdotai/toolslm', types='py', skip_file_re='^_', out=False, files_only=True))\n\n{'00_xml.ipynb': 39890, '01_funccall.ipynb': 66266, '02_shell.ipynb': 6295, '03_download.ipynb': 12178, '04_md_hier.ipynb': 8469, 'index.ipynb': 3089, 'setup.py': 2596, 'samples/sample_core.py': 134, 'toolslm/download.py': 4582, 'toolslm/funccall.py': 11650, 'toolslm/md_hier.py': 11010, 'toolslm/shell.py': 1617, 'toolslm/xml.py': 13718}\n\n\n\nprint(repo2ctx('https://github.com/AnswerDotAI/toolslm/tree/main/samples'))\n\n&lt;documents title=\"GitHub repository contents from AnswerDotAI/toolslm/main/samples\"&gt;&lt;document index=\"1\"&gt;&lt;src&gt;\nsample_core.py\n&lt;/src&gt;&lt;document-content&gt;\nimport inspect\nempty = inspect.Parameter.empty\nmodels = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n&lt;/document-content&gt;&lt;/document&gt;&lt;document index=\"2\"&gt;&lt;src&gt;\nsample_styles.css\n&lt;/src&gt;&lt;document-content&gt;\n.cell { margin-bottom: 1rem; }\n.cell &gt; .sourceCode { margin-bottom: 0; }\n.cell-output &gt; pre { margin-bottom: 0; }\n&lt;/document-content&gt;&lt;/document&gt;&lt;/documents&gt;",
    "crumbs": [
      "xml source"
    ]
  }
]