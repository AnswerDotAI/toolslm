# Download helpers


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
from IPython.display import Markdown,HTML
from fastcore.test import *
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L13"
target="_blank" style="float:right; font-size:smaller">source</a>

### clean_md

>  clean_md (text, rm_comments=True, rm_details=True)

*Remove comments and `<details>` sections from `text`*

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L21"
target="_blank" style="float:right; font-size:smaller">source</a>

### read_md

>  read_md (url, rm_comments=True, rm_details=True,
>               params:QueryParamTypes|None=None, headers:HeaderTypes|None=None,
>               cookies:CookieTypes|None=None, auth:AuthTypes|None=None,
>               proxy:ProxyTypes|None=None, follow_redirects:bool=False,
>               verify:ssl.SSLContext|str|bool=True,
>               timeout:TimeoutTypes=Timeout(timeout=5.0), trust_env:bool=True)

*Read text from `url` and clean with `clean_docs`*

``` python
mdurl = 'https://claudette.answer.ai/index.html.md'
md = read_md(mdurl)
# Markdown(md)
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L26"
target="_blank" style="float:right; font-size:smaller">source</a>

### html2md

>  html2md (s:str, ignore_links=True)

*Convert `s` from HTML to markdown*

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L36"
target="_blank" style="float:right; font-size:smaller">source</a>

### read_html

>  read_html (url, sel=None, rm_comments=True, rm_details=True, multi=False,
>                 wrap_tag=None, ignore_links=True)

*Get `url`, optionally selecting CSS selector `sel`, and convert to
clean markdown*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>url</td>
<td></td>
<td></td>
<td>URL to read</td>
</tr>
<tr>
<td>sel</td>
<td>NoneType</td>
<td>None</td>
<td>Read only outerHTML of CSS selector <code>sel</code></td>
</tr>
<tr>
<td>rm_comments</td>
<td>bool</td>
<td>True</td>
<td>Removes HTML comments</td>
</tr>
<tr>
<td>rm_details</td>
<td>bool</td>
<td>True</td>
<td>Removes <code>&lt;details&gt;</code> tags</td>
</tr>
<tr>
<td>multi</td>
<td>bool</td>
<td>False</td>
<td>Get all matches to <code>sel</code> or first one</td>
</tr>
<tr>
<td>wrap_tag</td>
<td>NoneType</td>
<td>None</td>
<td>If multi, each selection wrapped with
<wrap_tag>content</wrap_tag></td>
</tr>
<tr>
<td>ignore_links</td>
<td>bool</td>
<td>True</td>
<td></td>
</tr>
</tbody>
</table>

``` python
# test single class selector
listings = read_html('https://www.answer.ai/', sel='.listing-description')
assert len(listings) < 500

# Test multi class selector
listings = read_html('https://www.answer.ai/', sel='.listing-description', multi=True)
assert len(listings) > 1000 # returns more than single so selecting multi

# Test multi_wrap_tag
listings = read_html('https://www.answer.ai/', sel='.listing-description', multi=True, wrap_tag='document')
assert '<document>' in listings and '</document>' in listings
```

``` python
read_html('https://www.answer.ai/', sel='.listing-description', ignore_links=False)
```

    '[My experience learning GPU programming, and implementing a new GPU education app in the process](./posts/2025-03-17-gpu-programming-scratch.html)\n\n'

``` python
# test tag css selectors
assert len(read_html('https://www.answer.ai/', sel='div.listing-description', multi=True)) > 1000
assert len(read_html('https://www.answer.ai/', sel='div', multi=True)) > 1000
```

``` python
htmlurl = 'https://hypermedia.systems/hypermedia-a-reintroduction/'
hmd = read_html(htmlurl)
assert len(hmd) > 100
# Markdown(hmd)
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L58"
target="_blank" style="float:right; font-size:smaller">source</a>

### get_llmstxt

>  get_llmstxt (url, optional=False, n_workers=None)

*Get llms.txt file from and expand it with `llms_txt.create_ctx()`*

``` python
# print(get_llmstxt('https://llmstxt.org/llms.txt'))
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L67"
target="_blank" style="float:right; font-size:smaller">source</a>

### split_url

>  split_url (url)

*Split `url` into base, path, and file name, normalising name to ‘/’ if
empty*

``` python
urls = ('https://claudette.answer.ai/path/', 'https://claudette.answer.ai/', 'https://llmstxt.org', 'https://llmstxt.org/')

[split_url(o) for o in urls]
```

    [('https://claudette.answer.ai', '', '/path'),
     ('https://claudette.answer.ai', '/', ''),
     ('https://llmstxt.org', '/', ''),
     ('https://llmstxt.org', '/', '')]

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L83"
target="_blank" style="float:right; font-size:smaller">source</a>

### find_docs

>  find_docs (url)

*If available, return LLM-friendly llms.txt context or markdown file
location from `url`*

``` python
fl_url = 'https://answerdotai.github.io/fastlite'
```

``` python
find_docs(fl_url)
```

    'https://answerdotai.github.io/fastlite/llms.txt'

``` python
for o in urls: print(find_docs(o))
```

    https://claudette.answer.ai/llms.txt
    https://claudette.answer.ai/llms.txt
    https://llmstxt.org/llms.txt
    https://llmstxt.org/llms.txt

``` python
suffixes = ["/", "/tmp", "/tmp/tmp/"]
for suff in suffixes:
    for o in urls:  test_eq(find_docs(o), find_docs(o+suff))

test_eq(find_docs("https://github.com"), "https://github.com/llms.txt")
test_eq(find_docs("https://github.com/AnswerDotAI"), "https://github.com/llms.txt")
test_eq(find_docs("https://github.com/AnswerDotAI/"), "https://github.com/llms.txt")
```

------------------------------------------------------------------------

<a
href="https://github.com/AnswerDotAI/toolslm/blob/main/toolslm/download.py#L103"
target="_blank" style="float:right; font-size:smaller">source</a>

### read_docs

>  read_docs (url, optional=False, n_workers=None, rm_comments=True,
>                 rm_details=True)

*If available, return LLM-friendly llms.txt context or markdown file
response for `url`*
