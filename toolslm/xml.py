# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_xml.ipynb.

# %% auto 0
__all__ = ['doctype', 'json_to_xml', 'get_mime_text', 'cell2out', 'cell2xml', 'cells2xml', 'nb2xml', 'get_docstring', 'py2sigs',
           'mk_doctype', 'mk_doc', 'docs_xml', 'read_file', 'files2ctx', 'folder2ctx', 'sym2file', 'sym2folderctx',
           'sym2pkgpath', 'sym2pkgctx', 'folder2ctx_cli', 'parse_gh_url', 'repo2ctx', 'repo2ctx_cli']

# %% ../00_xml.ipynb
import hashlib, inspect, xml.etree.ElementTree as ET, ast
from collections import namedtuple
from ghapi.all import GhApi

from fastcore.utils import *
from fastcore.meta import delegates
from fastcore.xtras import hl_md
from fastcore.xml import to_xml, Document, Documents, Document_content, Src, Source,Out,Outs,Cell,Notebook,Md,Code,Raw
from fastcore.script import call_parse

# %% ../00_xml.ipynb
def json_to_xml(d:dict, # JSON dictionary to convert
                rnm:str # Root name
               )->str:
    "Convert `d` to XML."
    root = ET.Element(rnm)
    def build_xml(data, parent):
        if isinstance(data, dict):
            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))
        elif isinstance(data, list):
            for item in data: build_xml(item, ET.SubElement(parent, 'item'))
        else: parent.text = str(data)
    build_xml(d, root)
    ET.indent(root)
    return ET.tostring(root, encoding='unicode')

# %% ../00_xml.ipynb
def get_mime_text(data):
    "Get text from MIME bundle, preferring markdown over plain"
    if 'text/markdown' in data: return ''.join(list(data['text/markdown']))
    if 'text/plain' in data: return ''.join(list(data['text/plain']))

# %% ../00_xml.ipynb
def cell2out(o):
    "Convert single notebook output to XML format"
    if hasattr(o, 'data'): 
        txt = get_mime_text(o.data)
        if txt: return Out(txt, mime='markdown' if 'text/markdown' in o.data else 'plain')
    if hasattr(o, 'text'):
        txt = o.text if isinstance(o.text, str) else ''.join(o.text)
        return Out(txt, type='stream', name=o.get('name', 'stdout'))
    if hasattr(o, 'ename'): return Out(f"{o.ename}: {o.evalue}", type='error')

# %% ../00_xml.ipynb
_ctfuns = {'code': Code, 'markdown': Md, 'raw': Raw}

def cell2xml(cell, out=True, ids=True, nums=False):
    "Convert notebook cell to concise XML format"
    src = ''.join(getattr(cell, 'source', ''))
    if nums: src = '\n'.join(f'{i+1:6d} â”‚ {l}' for i,l in enumerate(src.splitlines()))
    f = _ctfuns[cell.cell_type]
    kw = dict(id=cell.id) if ids and hasattr(cell, 'id') else {}
    if not out: return f(src, **kw)
    parts = [Source(src)]
    out_items = L(getattr(cell,'outputs',[])).map(cell2out).filter()
    if out_items: parts.append(Outs(*out_items))
    return f(*parts, **kw)

# %% ../00_xml.ipynb
@delegates(cell2xml)
def cells2xml(cells, wrap=Notebook, **kwargs):
    "Convert notebook to XML format"
    res = [cell2xml(c, **kwargs) for c in cells]
    return to_xml(wrap(*res), do_escape=False)

@delegates(cell2xml)
def nb2xml(fname=None, nb=None, **kwargs):
    "Convert notebook to XML format"
    assert bool(fname)^bool(nb), "Pass either `fname` or `nb`"
    if not nb: nb = dict2obj(fname.read_json())
    return cells2xml(nb.cells, **kwargs)

# %% ../00_xml.ipynb
def get_docstring(node, lines):
    "Get docstring from source lines if present"
    if not (node.body and isinstance(node.body[0], ast.Expr) and isinstance(node.body[0].value, ast.Constant)): return None
    doc_node = node.body[0]
    return '\n'.join(lines[doc_node.lineno-1:doc_node.end_lineno])

def py2sigs(fname=None, src=None):
    "Return signature+docstring text for all functions and class methods in source"
    if fname: src = Path(fname).expanduser().read_text()
    tree = ast.parse(src)
    lines = src.splitlines()
    res = []
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            body_start = max(node.body[0].lineno - 1, node.lineno)
            sig = '\n'.join(lines[node.lineno-1:body_start])
            doc = get_docstring(node, lines)
            cts = f"{sig}\n{doc}" if doc else sig
            res.append(cts.strip('\r\n'))
    return '\n\n'.join(res)

# %% ../00_xml.ipynb
doctype = namedtuple('doctype', ['src', 'content'])

# %% ../00_xml.ipynb
def _add_nls(s):
    "Add newlines to start and end of `s` if missing"
    if not s: return s
    if s[ 0]!='\n': s = '\n'+s
    if s[-1]!='\n': s = s+'\n'
    return s

# %% ../00_xml.ipynb
def mk_doctype(content:str,  # The document content
           src:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided
          ) -> namedtuple:
    "Create a `doctype` named tuple"
    if src is None: src = hashlib.md5(content.encode()).hexdigest()[:8]
    return doctype(_add_nls(str(src).strip()), _add_nls(content.strip()))

# %% ../00_xml.ipynb
def mk_doc(index:int,  # The document index
           content:str,  # The document content
           src:Optional[str]=None, # URL, filename, etc; defaults to `md5(content)` if not provided
           **kwargs
          ) -> tuple:
    "Create an `ft` format tuple for a single doc in Anthropic's recommended format"
    dt = mk_doctype(content, src)
    content = Document_content(NotStr(dt.content))
    src = Src(NotStr(dt.src))
    return Document(src, content, index=index, **kwargs)

# %% ../00_xml.ipynb
def docs_xml(docs:list[str],  # The content of each document
             srcs:Optional[list]=None,  # URLs, filenames, etc; each one defaults to `md5(content)` if not provided
             prefix:bool=False, # Include Anthropic's suggested prose intro?
             details:Optional[list]=None, # Optional list of dicts with additional attrs for each doc
             title:str=None # Optional title attr for Documents element
            )->str:
    "Create an XML string containing `docs` in Anthropic's recommended format"
    pre = 'Here are some documents for you to reference for your task:\n\n' if prefix else ''
    if srcs is None: srcs = [None]*len(docs)
    if details is None: details = [{}]*len(docs)
    docs = (mk_doc(i+1, d, s, **kw) for i,(d,s,kw) in enumerate(zip(docs,srcs,details)) if d.strip())
    kw = dict(title=title) if title else {}
    return pre + to_xml(Documents(*docs, **kw), do_escape=False)

# %% ../00_xml.ipynb
@delegates(nb2xml)
def read_file(fname, max_size=None, sigs_only=False, **kwargs):
    "Read file content, converting notebooks to XML if needed"
    fname = Path(fname).expanduser()
    if fname.suffix == '.ipynb': res = nb2xml(fname, **kwargs)
    elif fname.suffix == '.py' and sigs_only: res = py2sigs(fname)
    else: res = fname.read_text()
    if max_size and len(res)>max_size: return f"[Skipped: {fname.name} exceeds {max_size} bytes]"
    return res

# %% ../00_xml.ipynb
@delegates(docs_xml)
def files2ctx(
    fnames:list[Union[str,Path]], # List of file names to add to context
    srcs:Optional[list]=None, # Use the labels instead of `fnames`
    max_size:int=None, # Skip files larger than this (bytes)
    out:bool=True, # Include notebook cell outputs?
    ids:bool=True,  # Include cell ids in notebooks?
    nums:bool=False, # Include line numbers in notebook cell source?
    sigs_only:bool=False, # For .py files, only include signatures and docstrings
    **kwargs
)->str: # XML for LM context
    "Convert files to XML context, handling notebooks"
    fnames = [Path(o).expanduser() for o in listify(fnames)]
    contents = [read_file(o, max_size=max_size, out=out, ids=ids, sigs_only=sigs_only, nums=nums) for o in fnames]
    return docs_xml(contents, srcs or fnames, **kwargs)

# %% ../00_xml.ipynb
@delegates(globtastic, but='func')
def folder2ctx(
    path:Union[str,Path], # Folder to read
    prefix:bool=False, # Include Anthropic's suggested prose intro?
    out:bool=True, # Include notebook cell outputs?
    include_base:bool=True, # Include full path in src?
    title:str=None, # Optional title attr for Documents element
    max_size:int=100_000, # Skip files larger than this (bytes)
    max_total:int=10_000_000,  # Max total output size in bytes
    readme_first:bool=False,  # Prioritize README files at start of context?
    files_only:bool=False,  # Return dict of {filename: size} instead of context?
    sigs_only:bool=False,  # Return signatures instead of full text for python files?
    ids:bool=True,  # Include cell ids in notebooks?
    **kwargs
)->Union[str,dict]:
    "Convert folder contents to XML context, handling notebooks"
    folder = Path(path).expanduser()
    fnames = pglob(folder, **kwargs)
    if files_only: return {str(f.relative_to(folder)): f.stat().st_size for f in fnames}
    if readme_first: fnames = sorted(fnames, key=lambda f: (0 if 'readme' in f.name.lower() else 1, f))
    srcs = fnames if include_base else [f.relative_to(folder) for f in fnames]
    res = files2ctx(fnames, prefix=prefix, out=out, srcs=srcs, title=title, max_size=max_size, sigs_only=sigs_only, ids=ids)
    suf = f"\n\n[TRUNCATED: output size {{_outsz_}} exceeded max size {max_total} bytes]"
    if max_total and len(res) > max_total: res = truncstr(res, max_total, suf=suf, sizevar='_outsz_')
    return res

# %% ../00_xml.ipynb
def sym2file(sym):
    "Return md string with filepath and contents for a symbol's source file"
    f = Path(inspect.getfile(sym))
    return f"- `{f}`\n\n````\n{f.read_text()}\n````"

# %% ../00_xml.ipynb
@delegates(folder2ctx)
def sym2folderctx(
    sym,
    types:str|list='py',  # list or comma-separated str of ext types from: py, js, java, c, cpp, rb, r, ex, sh, web, doc, cfg
    skip_file_re=r'^_mod',
    **kwargs):
    "Return folder context for a symbol's source file location"
    return folder2ctx(Path(inspect.getfile(sym)).parent, types=types, skip_file_re=skip_file_re, **kwargs)

# %% ../00_xml.ipynb
def sym2pkgpath(sym):
    "Get root package path for a symbol"
    root = sym.__module__.split('.')[0]
    return Path(sys.modules[root].__path__[0])

# %% ../00_xml.ipynb
@delegates(folder2ctx)
def sym2pkgctx(sym, types:str|list='py', skip_file_re=r'^_mod', **kwargs):
    "Return repo context for a symbol's root package"
    return folder2ctx(sym2pkgpath(sym), types=types, skip_file_re=skip_file_re, **kwargs)

# %% ../00_xml.ipynb
@call_parse
@delegates(folder2ctx)
def folder2ctx_cli(
    path:str='.', # Folder name containing files to add to context
    out:bool=True, # Include notebook cell outputs?
    **kwargs # Passed to `folder2ctx`
)->str: # XML for Claude context
    "CLI to convert folder contents to XML context, handling notebooks"
    print(folder2ctx(path, out=out, **kwargs))

# %% ../00_xml.ipynb
def parse_gh_url(url):
    "Parse GitHub URL into (owner, repo, type, ref, path) or None"
    m = re.match(r'https?://(?:www\.)?github\.com/([^/]+)/([^/]+)(?:/([^/]+)(?:/([^/]+)(?:/(.+))?)?)?', url)
    return dict(zip('owner repo typ ref path'.split(), m.groups())) if m else None

# %% ../00_xml.ipynb
@delegates(folder2ctx)
def repo2ctx(
    owner:str,  # GitHub repo owner or "owner/repo" or a full github URL
    repo:str=None,   # GitHub repo name (leave empty if using "owner/repo" or URL format for owner param)
    ref:str=None,  # Git ref (branch/tag/sha) (get from URL not provided); defaults to repo's default branch
    folder:str=None,  # Only include files under this path (get from URL not provided)
    show_filters:bool=True,  # Include filter info in title?
    token:str=None,  # GitHub token (uses GITHUB_TOKEN env var if None)
    **kwargs  # Passed to `folder2ctx`
)->Union[str,dict]:  # XML for LM context, or dict of file sizes
    "Convert GitHub repo to XML context without cloning"
    import tempfile, tarfile, io
    if owner.startswith('http'):
        parsed = parse_gh_url(owner)
        if not parsed: raise ValueError(f"Invalid GitHub URL: {owner}")
        owner,repo = parsed['owner'], parsed['repo']
        ref = ref or parsed.get('ref')
        folder = folder or parsed.get('path')
    if repo is None: owner, repo = owner.split('/')
    api = GhApi(token=token)
    if ref is None: ref = api.repos.get(owner, repo).default_branch
    data = api.repos.download_tarball_archive(owner, repo, ref)
    title = f"GitHub repository contents from {owner}/{repo}/{ref}"
    if folder: title += f'/{folder}'
    if show_filters:
        parts = [f"{k}: {', '.join(v) if isinstance(v, (list,tuple)) else v}" for k,v in kwargs.items() if v]
        if parts: title += f" (filters applied -- {' | '.join(parts)})"
    tf = tarfile.open(fileobj=io.BytesIO(data))
    with tempfile.TemporaryDirectory() as tmp:
        tf.extractall(tmp, filter='data')
        subdir = Path(tmp) / tf.getmembers()[0].name.split('/')[0]
        if folder: subdir = subdir/folder
        return folder2ctx(subdir, include_base=False, title=title, readme_first=True, **kwargs)

# %% ../00_xml.ipynb
@call_parse
@delegates(repo2ctx, but='include_base,title,readme_first')
def repo2ctx_cli(
    owner:str,  # GitHub repo owner or "owner/repo" or a full github URL
    repo:str=None,   # GitHub repo name (leave empty if using "owner/repo" or URL format)
    ref:str=None,  # Git ref (branch/tag/sha)
    folder:str=None,  # Only include files under this path
    out:bool=True, # Include notebook cell outputs?
    **kwargs # Passed to `repo2ctx`
)->str: # XML for Claude context
    "CLI to convert GitHub repo contents to XML context"
    print(repo2ctx(owner, repo, ref=ref, folder=folder, out=out, **kwargs))
