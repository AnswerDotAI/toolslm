# AUTOGENERATED! DO NOT EDIT! File to edit: ../00_xml.ipynb.

# %% auto 0
__all__ = ['doctype', 'json_to_xml', 'get_mime_text', 'cell2out', 'cell2xml', 'nb2xml', 'mk_doctype', 'mk_doc', 'docs_xml',
           'read_file', 'files2ctx', 'folder2ctx', 'repo2ctx', 'folder2ctx_cli']

# %% ../00_xml.ipynb
import hashlib,xml.etree.ElementTree as ET
from collections import namedtuple
from ghapi.all import GhApi

from fastcore.utils import *
from fastcore.meta import delegates
from fastcore.xtras import hl_md
from fastcore.xml import to_xml, Document, Documents, Document_content, Src, Source,Out,Outs,Cell,Notebook,Md,Code
from fastcore.script import call_parse

# %% ../00_xml.ipynb
def json_to_xml(d:dict, # JSON dictionary to convert
                rnm:str # Root name
               )->str:
    "Convert `d` to XML."
    root = ET.Element(rnm)
    def build_xml(data, parent):
        if isinstance(data, dict):
            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))
        elif isinstance(data, list):
            for item in data: build_xml(item, ET.SubElement(parent, 'item'))
        else: parent.text = str(data)
    build_xml(d, root)
    ET.indent(root)
    return ET.tostring(root, encoding='unicode')

# %% ../00_xml.ipynb
def get_mime_text(data):
    "Get text from MIME bundle, preferring markdown over plain"
    if 'text/markdown' in data: return ''.join(list(data['text/markdown']))
    if 'text/plain' in data: return ''.join(list(data['text/plain']))

# %% ../00_xml.ipynb
def cell2out(o):
    "Convert single notebook output to XML format"
    if hasattr(o, 'data'): 
        txt = get_mime_text(o.data)
        if txt: return Out(txt, mime='markdown' if 'text/markdown' in o.data else 'plain')
    if hasattr(o, 'text'):
        txt = o.text if isinstance(o.text, str) else ''.join(o.text)
        return Out(txt, type='stream', name=o.get('name', 'stdout'))
    if hasattr(o, 'ename'): return Out(f"{o.ename}: {o.evalue}", type='error')

# %% ../00_xml.ipynb
def cell2xml(cell, out=True):
    "Convert notebook cell to concise XML format"
    src = ''.join(getattr(cell, 'source', ''))
    f = Code if cell.cell_type=='code' else Md
    if not out: return f(src)
    parts = [Source(src)]
    out_items = L(getattr(cell,'outputs',[])).map(cell2out).filter()
    if out_items: parts.append(Outs(*out_items))
    return f(*parts)

# %% ../00_xml.ipynb
def nb2xml(fname=None, nb=None, out=True):
    "Convert notebook to XML format"
    assert bool(fname)^bool(nb), "Pass either `fname` or `nb`"
    if not nb: nb = dict2obj(fname.read_json())
    cells_xml = [to_xml(cell2xml(c, out=out), do_escape=False) for c in nb.cells if c.cell_type in ('code','markdown')]
    return to_xml(Notebook(*cells_xml), do_escape=False)

# %% ../00_xml.ipynb
doctype = namedtuple('doctype', ['src', 'content'])

# %% ../00_xml.ipynb
def _add_nls(s):
    "Add newlines to start and end of `s` if missing"
    if not s: return s
    if s[ 0]!='\n': s = '\n'+s
    if s[-1]!='\n': s = s+'\n'
    return s

# %% ../00_xml.ipynb
def mk_doctype(content:str,  # The document content
           src:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided
          ) -> namedtuple:
    "Create a `doctype` named tuple"
    if src is None: src = hashlib.md5(content.encode()).hexdigest()[:8]
    return doctype(_add_nls(str(src).strip()), _add_nls(content.strip()))

# %% ../00_xml.ipynb
def mk_doc(index:int,  # The document index
           content:str,  # The document content
           src:Optional[str]=None, # URL, filename, etc; defaults to `md5(content)` if not provided
           **kwargs
          ) -> tuple:
    "Create an `ft` format tuple for a single doc in Anthropic's recommended format"
    dt = mk_doctype(content, src)
    content = Document_content(NotStr(dt.content))
    src = Src(NotStr(dt.src))
    return Document(src, content, index=index, **kwargs)

# %% ../00_xml.ipynb
def docs_xml(docs:list[str],  # The content of each document
             srcs:Optional[list]=None,  # URLs, filenames, etc; each one defaults to `md5(content)` if not provided
             prefix:bool=True, # Include Anthropic's suggested prose intro?
             details:Optional[list]=None, # Optional list of dicts with additional attrs for each doc
             title:str=None # Optional title attr for Documents element
            )->str:
    "Create an XML string containing `docs` in Anthropic's recommended format"
    pre = 'Here are some documents for you to reference for your task:\n\n' if prefix else ''
    if srcs is None: srcs = [None]*len(docs)
    if details is None: details = [{}]*len(docs)
    docs = (mk_doc(i+1, d, s, **kw) for i,(d,s,kw) in enumerate(zip(docs,srcs,details)))
    kw = dict(title=title) if title else {}
    return pre + to_xml(Documents(*docs, **kw), do_escape=False)

# %% ../00_xml.ipynb
def read_file(fname, out=True, max_size=None):
    "Read file content, converting notebooks to XML if needed"
    fname = Path(fname)
    if fname.suffix == '.ipynb': res = nb2xml(fname, out=out)
    else: res = fname.read_text()
    if max_size and len(res)>max_size: return f"[Skipped: {fname.name} exceeds {max_size} bytes]"
    return res

# %% ../00_xml.ipynb
def files2ctx(
    fnames:list[Union[str,Path]], # List of file names to add to context
    prefix:bool=True, # Include Anthropic's suggested prose intro?
    out:bool=True, # Include notebook cell outputs?
    srcs:Optional[list]=None, # Use the labels instead of `fnames`
    title:str=None, # Optional title attr for Documents element
    max_size:int=None # Skip files larger than this (bytes)
)->str: # XML for LM context
    "Convert files to XML context, handling notebooks"
    fnames = [Path(o) for o in fnames]
    contents = [read_file(o, out=out, max_size=max_size) for o in fnames]
    return docs_xml(contents, srcs or fnames, prefix=prefix, title=title)

# %% ../00_xml.ipynb
@delegates(globtastic)
def folder2ctx(
    folder:Union[str,Path],
    prefix:bool=True, # Include Anthropic's suggested prose intro?
    out:bool=True, # Include notebook cell outputs?
    include_base:bool=True, # Include full path in src?
    title:str=None, # Optional title attr for Documents element
    max_size:int=100_000, # Skip files larger than this (bytes)
    **kwargs
)->str:
    "Convert folder contents to XML context, handling notebooks"
    folder = Path(folder)
    fnames = globtastic(folder, **kwargs)
    srcs = fnames if include_base else [Path(f).relative_to(folder) for f in fnames]
    return files2ctx(fnames, prefix=prefix, out=out, srcs=srcs, title=title, max_size=max_size)

# %% ../00_xml.ipynb
@delegates(folder2ctx)
def repo2ctx(
    owner:str,  # GitHub repo owner
    repo:str,   # GitHub repo name
    ref:str=None,  # Git ref (branch/tag/sha); defaults to repo's default branch
    **kwargs  # Passed to `folder2ctx`
)->str:  # XML for LM context
    "Convert GitHub repo to XML context without cloning"
    import tempfile, tarfile, io
    api = GhApi()
    if ref is None: ref = api.repos.get(owner, repo).default_branch
    data = api.repos.download_tarball_archive(owner, repo, ref)
    parts = ' | '.join(f"{k}: {', '.join(v) if isinstance(v, (list,tuple)) else v}"
        for k,v in kwargs.items() if v)
    title = f"GitHub repository contents from {owner}/{repo} at ref '{ref}'"
    if parts: title += f" (filters applied: {parts})"
    tf = tarfile.open(fileobj=io.BytesIO(data))
    with tempfile.TemporaryDirectory() as tmp:
        tf.extractall(tmp, filter='data')
        subdir = Path(tmp) / tf.getmembers()[0].name.split('/')[0]
        return folder2ctx(subdir, include_base=False, title=title, **kwargs)

# %% ../00_xml.ipynb
@call_parse
@delegates(folder2ctx)
def folder2ctx_cli(
    folder:str, # Folder name containing files to add to context
    out:bool=True, # Include notebook cell outputs?
    **kwargs # Passed to `folder2ctx`
)->str: # XML for Claude context
    "CLI to convert folder contents to XML context, handling notebooks"
    print(folder2ctx(folder, out=out, **kwargs))
