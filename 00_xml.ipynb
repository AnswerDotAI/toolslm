{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe78920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp xml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d773712-12fe-440e-891f-36f59666dfde",
   "metadata": {},
   "source": [
    "# xml source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import hashlib,xml.etree.ElementTree as ET\n",
    "from collections import namedtuple\n",
    "from ghapi.all import GhApi\n",
    "\n",
    "from fastcore.utils import *\n",
    "from fastcore.meta import delegates\n",
    "from fastcore.xtras import hl_md\n",
    "from fastcore.xml import to_xml, Document, Documents, Document_content, Src, Source,Out,Outs,Cell,Notebook,Md,Code\n",
    "from fastcore.script import call_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545891d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ba7bd",
   "metadata": {},
   "source": [
    "## JSON to XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def json_to_xml(d:dict, # JSON dictionary to convert\n",
    "                rnm:str # Root name\n",
    "               )->str:\n",
    "    \"Convert `d` to XML.\"\n",
    "    root = ET.Element(rnm)\n",
    "    def build_xml(data, parent):\n",
    "        if isinstance(data, dict):\n",
    "            for key, value in data.items(): build_xml(value, ET.SubElement(parent, key))\n",
    "        elif isinstance(data, list):\n",
    "            for item in data: build_xml(item, ET.SubElement(parent, 'item'))\n",
    "        else: parent.text = str(data)\n",
    "    build_xml(d, root)\n",
    "    ET.indent(root)\n",
    "    return ET.tostring(root, encoding='unicode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a35a2",
   "metadata": {},
   "source": [
    "JSON doesn't map as nicely to XML as the data structure used in `fastcore.xml`, but for simple XML trees it can be convenient -- for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a5be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```xml\n",
       "<person>\n",
       "  <surname>Howard</surname>\n",
       "  <firstnames>\n",
       "    <item>Jeremy</item>\n",
       "    <item>Peter</item>\n",
       "  </firstnames>\n",
       "  <address>\n",
       "    <state>Queensland</state>\n",
       "    <country>Australia</country>\n",
       "  </address>\n",
       "</person>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dict(surname='Howard', firstnames=['Jeremy','Peter'],\n",
    "         address=dict(state='Queensland',country='Australia'))\n",
    "hl_md(json_to_xml(a, 'person'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788c48c",
   "metadata": {},
   "source": [
    "## Including documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869126b2",
   "metadata": {},
   "source": [
    "### Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa0fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "{ 'cell_type': 'code',\n",
       "  'execution_count': {},\n",
       "  'id': '1e9ee5c1',\n",
       "  'metadata': {},\n",
       "  'outputs': [],\n",
       "  'source': ['#|hide\\n', '#|eval: false\\n', 'from nbdev.doclinks import nbdev_export\\n', 'nbdev_export()']}\n",
       "```"
      ],
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': {},\n",
       " 'id': '1e9ee5c1',\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': ['#|hide\\n', '#|eval: false\\n', 'from nbdev.doclinks import nbdev_export\\n', 'nbdev_export()']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbp = Path('00_xml.ipynb')\n",
    "nb = dict2obj(nbp.read_json())\n",
    "cells = nb.cells\n",
    "cell = cells[-1]\n",
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338af2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_mime_text(data):\n",
    "    \"Get text from MIME bundle, preferring markdown over plain\"\n",
    "    if 'text/markdown' in data: return ''.join(list(data['text/markdown']))\n",
    "    if 'text/plain' in data: return ''.join(list(data['text/plain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff831f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cell2out(o):\n",
    "    \"Convert single notebook output to XML format\"\n",
    "    if hasattr(o, 'data'): \n",
    "        txt = get_mime_text(o.data)\n",
    "        if txt: return Out(txt, mime='markdown' if 'text/markdown' in o.data else 'plain')\n",
    "    if hasattr(o, 'text'):\n",
    "        txt = o.text if isinstance(o.text, str) else ''.join(o.text)\n",
    "        return Out(txt, type='stream', name=o.get('name', 'stdout'))\n",
    "    if hasattr(o, 'ename'): return Out(f\"{o.ename}: {o.evalue}\", type='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in cell.outputs: print(to_xml(cell2out(o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a87081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cell2xml(cell, out=True):\n",
    "    \"Convert notebook cell to concise XML format\"\n",
    "    src = ''.join(getattr(cell, 'source', ''))\n",
    "    f = Code if cell.cell_type=='code' else Md\n",
    "    if not out: return f(src)\n",
    "    parts = [Source(src)]\n",
    "    out_items = L(getattr(cell,'outputs',[])).map(cell2out).filter()\n",
    "    if out_items: parts.append(Outs(*out_items))\n",
    "    return f(*parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce3d825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```html\n",
       "<code><source>#|hide\n",
       "#|eval: false\n",
       "from nbdev.doclinks import nbdev_export\n",
       "nbdev_export()</code>\n",
       "```"
      ],
      "text/plain": [
       "code((source(('#|hide\\n#|eval: false\\nfrom nbdev.doclinks import nbdev_export\\nnbdev_export()',),{}),),{})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell2xml(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4fdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```html\n",
       "<code>#|hide\n",
       "#|eval: false\n",
       "from nbdev.doclinks import nbdev_export\n",
       "nbdev_export()</code>\n",
       "```"
      ],
      "text/plain": [
       "code(('#|hide\\n#|eval: false\\nfrom nbdev.doclinks import nbdev_export\\nnbdev_export()',),{})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell2xml(cell, out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861641af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def nb2xml(fname=None, nb=None, out=True):\n",
    "    \"Convert notebook to XML format\"\n",
    "    assert bool(fname)^bool(nb), \"Pass either `fname` or `nb`\"\n",
    "    if not nb: nb = dict2obj(fname.read_json())\n",
    "    cells_xml = [to_xml(cell2xml(c, out=out), do_escape=False) for c in nb.cells if c.cell_type in ('code','markdown')]\n",
    "    return to_xml(Notebook(*cells_xml), do_escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ceb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<notebook><code><source>#|default_exp xml</code><md><source># xml source</md></notebook>\n"
     ]
    }
   ],
   "source": [
    "nbsml = deepcopy(nb)\n",
    "del(nbsml.cells[2:])\n",
    "\n",
    "print(nb2xml(nb=nbsml))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69476b34",
   "metadata": {},
   "source": [
    "### Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479be4c9",
   "metadata": {},
   "source": [
    "According [to Anthropic](https://docs.anthropic.com/claude/docs/long-context-window-tips), \"*it's essential to structure your prompts in a way that clearly separates the input data from the instructions*\". They recommend using something like the following:\n",
    "\n",
    "```xml\n",
    "Here are some documents for you to reference for your task:\n",
    "    \n",
    "<documents>\n",
    "<document index=\"1\">\n",
    "<source>\n",
    "(URL, file name, hash, etc)\n",
    "</source>\n",
    "<document_content>\n",
    "(the text content)\n",
    "</document_content>\n",
    "</document>\n",
    "</documents>\n",
    "```\n",
    "\n",
    "We will create some small helper functions to make it easier to generate context in this format, although we're use `<src>` instead of `<source>` to avoid conflict with that HTML tag. Although it's based on Anthropic's recommendation, it's likely to work well with other models too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01dc320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "doctype = namedtuple('doctype', ['src', 'content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620a123",
   "metadata": {},
   "source": [
    "We'll use `doctype` to store our pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce853491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_nls(s):\n",
    "    \"Add newlines to start and end of `s` if missing\"\n",
    "    if not s: return s\n",
    "    if s[ 0]!='\\n': s = '\\n'+s\n",
    "    if s[-1]!='\\n': s = s+'\\n'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d3b06",
   "metadata": {},
   "source": [
    "Since Anthropic's example shows newlines before and after each tag, we'll do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fddbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<src>a</src>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_xml(Src('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac81ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<document>a</document>'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_xml(Document('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_doctype(content:str,  # The document content\n",
    "           src:Optional[str]=None # URL, filename, etc; defaults to `md5(content)` if not provided\n",
    "          ) -> namedtuple:\n",
    "    \"Create a `doctype` named tuple\"\n",
    "    if src is None: src = hashlib.md5(content.encode()).hexdigest()[:8]\n",
    "    return doctype(_add_nls(str(src).strip()), _add_nls(content.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8800921b",
   "metadata": {},
   "source": [
    "This is a convenience wrapper to ensure that a `doctype` has the needed information in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doctype(src='\\n47e19350\\n', content='\\nThis is a \"sample\"\\n')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = 'This is a \"sample\"'\n",
    "mk_doctype(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e454db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mk_doc(index:int,  # The document index\n",
    "           content:str,  # The document content\n",
    "           src:Optional[str]=None, # URL, filename, etc; defaults to `md5(content)` if not provided\n",
    "           **kwargs\n",
    "          ) -> tuple:\n",
    "    \"Create an `ft` format tuple for a single doc in Anthropic's recommended format\"\n",
    "    dt = mk_doctype(content, src)\n",
    "    content = Document_content(NotStr(dt.content))\n",
    "    src = Src(NotStr(dt.src))\n",
    "    return Document(src, content, index=index, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6ac26",
   "metadata": {},
   "source": [
    "We can now generate XML for one document in the suggested format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```html\n",
       "<document index=\"1\" title=\"test\"><src>\n",
       "47e19350\n",
       "</src><document-content>\n",
       "This is a \"sample\"\n",
       "</document-content></document>\n",
       "```"
      ],
      "text/plain": [
       "document((src(('\\n47e19350\\n',),{}), document-content(('\\nThis is a \"sample\"\\n',),{})),{'index': 1, 'title': 'test'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_doc(1, doc, title=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32237f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def docs_xml(docs:list[str],  # The content of each document\n",
    "             srcs:Optional[list]=None,  # URLs, filenames, etc; each one defaults to `md5(content)` if not provided\n",
    "             prefix:bool=False, # Include Anthropic's suggested prose intro?\n",
    "             details:Optional[list]=None, # Optional list of dicts with additional attrs for each doc\n",
    "             title:str=None # Optional title attr for Documents element\n",
    "            )->str:\n",
    "    \"Create an XML string containing `docs` in Anthropic's recommended format\"\n",
    "    pre = 'Here are some documents for you to reference for your task:\\n\\n' if prefix else ''\n",
    "    if srcs is None: srcs = [None]*len(docs)\n",
    "    if details is None: details = [{}]*len(docs)\n",
    "    docs = (mk_doc(i+1, d, s, **kw) for i,(d,s,kw) in enumerate(zip(docs,srcs,details)))\n",
    "    kw = dict(title=title) if title else {}\n",
    "    return pre + to_xml(Documents(*docs, **kw), do_escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85004124",
   "metadata": {},
   "source": [
    "Putting it all together, we have our final XML format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<documents><document index=\"1\"><src>\n",
      "47e19350\n",
      "</src><document-content>\n",
      "This is a \"sample\"\n",
      "</document-content></document><document index=\"2\"><src>\n",
      "doc.txt\n",
      "</src><document-content>\n",
      "And another one\n",
      "</document-content></document></documents>\n"
     ]
    }
   ],
   "source": [
    "docs = [doc, 'And another one']\n",
    "srcs = [None, 'doc.txt']\n",
    "print(docs_xml(docs, srcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8a7a9a",
   "metadata": {},
   "source": [
    "## Context creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06b2dc",
   "metadata": {},
   "source": [
    "Now that we can generate Anthropic's XML format, let's make it easy for a few common cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65317fc6",
   "metadata": {},
   "source": [
    "### File list to context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3778e8ed",
   "metadata": {},
   "source": [
    "For generating XML context from files, we'll just read them as text and use the file names as `src`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8581969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_file(fname, out=True, max_size=None):\n",
    "    \"Read file content, converting notebooks to XML if needed\"\n",
    "    fname = Path(fname)\n",
    "    if fname.suffix == '.ipynb': res = nb2xml(fname, out=out)\n",
    "    else: res = fname.read_text()\n",
    "    if max_size and len(res)>max_size: return f\"[Skipped: {fname.name} exceeds {max_size} bytes]\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(docs_xml)\n",
    "def files2ctx(\n",
    "    fnames:list[Union[str,Path]], # List of file names to add to context\n",
    "    out:bool=True, # Include notebook cell outputs?\n",
    "    srcs:Optional[list]=None, # Use the labels instead of `fnames`\n",
    "    max_size:int=None, # Skip files larger than this (bytes)\n",
    "    **kwargs\n",
    ")->str: # XML for LM context\n",
    "    \"Convert files to XML context, handling notebooks\"\n",
    "    fnames = [Path(o) for o in fnames]\n",
    "    contents = [read_file(o, out=out, max_size=max_size) for o in fnames]\n",
    "    return docs_xml(contents, srcs or fnames, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf73d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```xml\n",
       "<documents><document index=\"1\"><src>\n",
       "samples/sample_core.py\n",
       "</src><document-content>\n",
       "[Skipped: sample_core.py exceeds 120 bytes]\n",
       "</document-content></document><document index=\"2\"><src>\n",
       "samples/sample_styles.css\n",
       "</src><document-content>\n",
       ".cell { margin-bottom: 1rem; }\n",
       ".cell > .sourceCode { margin-bottom: 0; }\n",
       ".cell-output > pre { margin-bottom: 0; }\n",
       "</document-content></document></documents>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = ['samples/sample_core.py', 'samples/sample_styles.css']\n",
    "hl_md(files2ctx(fnames, max_size=120))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ddb2b",
   "metadata": {},
   "source": [
    "### Folder to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97bc488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(globtastic)\n",
    "def folder2ctx(\n",
    "    folder:Union[str,Path], # Folder to read\n",
    "    prefix:bool=False, # Include Anthropic's suggested prose intro?\n",
    "    out:bool=True, # Include notebook cell outputs?\n",
    "    include_base:bool=True, # Include full path in src?\n",
    "    title:str=None, # Optional title attr for Documents element\n",
    "    max_size:int=100_000, # Skip files larger than this (bytes)\n",
    "    max_total:int=10_000_000,  # Max total output size in bytes\n",
    "    readme_first:bool=False,  # Prioritize README files at start of context?\n",
    "    files_only:bool=False,  # Return dict of {filename: size} instead of context?\n",
    "    **kwargs\n",
    ")->Union[str,dict]:\n",
    "    \"Convert folder contents to XML context, handling notebooks\"\n",
    "    folder = Path(folder)\n",
    "    fnames = globtastic(folder, **kwargs)\n",
    "    if files_only: return {str(Path(f).relative_to(folder)): Path(f).stat().st_size for f in fnames}\n",
    "    if readme_first: fnames = sorted(fnames, key=lambda f: (0 if 'readme' in Path(f).name.lower() else 1, f))\n",
    "    srcs = fnames if include_base else [Path(f).relative_to(folder) for f in fnames]\n",
    "    res = files2ctx(fnames, prefix=prefix, out=out, srcs=srcs, title=title, max_size=max_size)\n",
    "    suf = f\"\\n\\n[TRUNCATED: output size {{_outsz_}} exceeded max size {max_total} bytes]\"\n",
    "    if max_total and len(res) > max_total: res = truncstr(res, max_total, suf=suf, sizevar='_outsz_')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd52392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some documents for you to reference for your task:\n",
      "\n",
      "<documents><document index=\"1\"><src>\n",
      "samples/sample_core.py\n",
      "</src><document-content>\n",
      "import inspect\n",
      "empty = inspect.Parameter.empty\n",
      "models = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n",
      "</document-content></document></documents>\n"
     ]
    }
   ],
   "source": [
    "print(folder2ctx('samples', prefix=True, file_glob='*.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a786c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "@call_parse\n",
    "@delegates(folder2ctx)\n",
    "def folder2ctx_cli(\n",
    "    folder:str, # Folder name containing files to add to context\n",
    "    out:bool=True, # Include notebook cell outputs?\n",
    "    **kwargs # Passed to `folder2ctx`\n",
    ")->str: # XML for Claude context\n",
    "    \"CLI to convert folder contents to XML context, handling notebooks\"\n",
    "    print(folder2ctx(folder, out=out, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbbe431",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "After you install `toolslm`, `folder2ctx` becomes available from the command line.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdc158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: folder2ctx [-h] [--recursive] [--symlinks] [--file_glob FILE_GLOB]\r\n",
      "                  [--file_re FILE_RE] [--folder_re FOLDER_RE]\r\n",
      "                  [--skip_file_glob SKIP_FILE_GLOB]\r\n",
      "                  [--skip_file_re SKIP_FILE_RE]\r\n",
      "                  [--skip_folder_re SKIP_FOLDER_RE] [--func FUNC]\r\n",
      "                  [--ret_folders] [--sort] [--exts EXTS] [--prefix] [--out]\r\n",
      "                  [--include_base] [--title TITLE] [--max_size MAX_SIZE]\r\n",
      "                  [--max_total MAX_TOTAL] [--readme_first]\r\n",
      "                  folder\r\n",
      "\r\n",
      "CLI to convert folder contents to XML context, handling notebooks\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  folder                           Folder name containing files to add to\r\n",
      "                                   context\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help                       show this help message and exit\r\n",
      "  --recursive                      search subfolders (default: False)\r\n",
      "  --symlinks                       follow symlinks? (default: False)\r\n",
      "  --file_glob FILE_GLOB            Only includ"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e files matching glob\r\n",
      "  --file_re FILE_RE                Only include files matching regex\r\n",
      "  --folder_re FOLDER_RE            Only enter folders matching regex\r\n",
      "  --skip_file_glob SKIP_FILE_GLOB  Skip files matching glob\r\n",
      "  --skip_file_re SKIP_FILE_RE      Skip files matching regex\r\n",
      "  --skip_folder_re SKIP_FOLDER_RE  Skip folders matching regex,\r\n",
      "  --func FUNC                      function to apply to each matched file\r\n",
      "                                   (default: <function join>)\r\n",
      "  --ret_folders                    return folders, not just files (default:\r\n",
      "                                   False)\r\n",
      "  --sort                           sort files by name within each folder\r\n",
      "                                   (default: False)\r\n",
      "  --exts EXTS\r\n",
      "  --prefix                         Include Anthropic's suggested prose intro?\r\n",
      "                                   (default: False)\r\n",
      "  --out                            Include notebook cell outputs? (default:\r\n",
      "                                   False)\r\n",
      "  --include_base                   Include full path in src? (default: False)\r\n",
      "  --title TITLE                    Optional title attr for Documents element\r\n",
      "  --max_size MAX_SIZE              Skip files larger than this (bytes) (default:\r\n",
      "                                   100000)\r\n",
      "  --max_total MAX_TOTAL            Max total output size in bytes (default:\r\n",
      "                                   10000000)\r\n",
      "  --readme_first                   Prioritize README files at start of context?\r\n",
      "                                   (default: False)\r\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "!folder2ctx -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ed2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_gh_url(url):\n",
    "    \"Parse GitHub URL into (owner, repo, type, ref, path) or None\"\n",
    "    m = re.match(r'https?://(?:www\\.)?github\\.com/([^/]+)/([^/]+)(?:/([^/]+)(?:/([^/]+)(?:/(.+))?)?)?', url)\n",
    "    return dict(zip('owner repo typ ref path'.split(), m.groups())) if m else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91934db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(folder2ctx)\n",
    "def repo2ctx(\n",
    "    owner:str,  # GitHub repo owner or \"owner/repo\" or a full github URL\n",
    "    repo:str=None,   # GitHub repo name (leave empty if using \"owner/repo\" or URL format for owner param)\n",
    "    ref:str=None,  # Git ref (branch/tag/sha) (get from URL not provided); defaults to repo's default branch\n",
    "    folder:str=None,  # Only include files under this path (get from URL not provided)\n",
    "    show_filters:bool=True,  # Include filter info in title?\n",
    "    token:str=None,  # GitHub token (uses GITHUB_TOKEN env var if None)\n",
    "    **kwargs  # Passed to `folder2ctx`\n",
    ")->Union[str,dict]:  # XML for LM context, or dict of file sizes\n",
    "    \"Convert GitHub repo to XML context without cloning\"\n",
    "    import tempfile, tarfile, io\n",
    "    if owner.startswith('http'):\n",
    "        parsed = parse_gh_url(owner)\n",
    "        if not parsed: raise ValueError(f\"Invalid GitHub URL: {owner}\")\n",
    "        owner,repo = parsed['owner'], parsed['repo']\n",
    "        ref = ref or parsed.get('ref')\n",
    "        folder = folder or parsed.get('path')\n",
    "    if repo is None: owner, repo = owner.split('/')\n",
    "    api = GhApi(token=token)\n",
    "    if ref is None: ref = api.repos.get(owner, repo).default_branch\n",
    "    data = api.repos.download_tarball_archive(owner, repo, ref)\n",
    "    title = f\"GitHub repository contents from {owner}/{repo}/{ref}\"\n",
    "    if folder: title += f'/{folder}'\n",
    "    if show_filters:\n",
    "        parts = [f\"{k}: {', '.join(v) if isinstance(v, (list,tuple)) else v}\" for k,v in kwargs.items() if v]\n",
    "        if parts: title += f\" (filters applied -- {' | '.join(parts)})\"\n",
    "    tf = tarfile.open(fileobj=io.BytesIO(data))\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        tf.extractall(tmp, filter='data')\n",
    "        subdir = Path(tmp) / tf.getmembers()[0].name.split('/')[0]\n",
    "        if folder: subdir = subdir/folder\n",
    "        return folder2ctx(subdir, include_base=False, title=title, readme_first=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af511990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<documents title=\"GitHub repository contents from answerdotai/toolslm/main (filters applied -- exts: ipynb, py | skip_file_re: ^_ | max_total: 500)\"><document index=\"1\"><src>\n",
      "00_xml.ipynb\n",
      "</src><document-content>\n",
      "<notebook><code>#|default_exp xml</code><md># xml source</md><code>#| export\n",
      "import hashlib,xml.etree.ElementTree as ET\n",
      "from collections import namedtuple\n",
      "from ghapi.all import GhApi\n",
      "\n",
      "from fastcore.utils import *\n",
      "from fastcore.\n",
      "\n",
      "[TRUNCATED: output size 90253 exceeded max size 500 bytes]\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(repo2ctx('answerdotai/toolslm', exts=('ipynb','py'), skip_file_re='^_', out=False, max_total=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7034308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00_xml.ipynb': 28232, '01_funccall.ipynb': 65902, '02_shell.ipynb': 6295, '03_download.ipynb': 12306, '04_md_hier.ipynb': 8091, 'index.ipynb': 3189, 'setup.py': 2596, 'samples/sample_core.py': 134, 'toolslm/download.py': 4451, 'toolslm/funccall.py': 11160, 'toolslm/md_hier.py': 11010, 'toolslm/shell.py': 1566, 'toolslm/xml.py': 8095}\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(repo2ctx('answerdotai/toolslm', exts=('ipynb','py'), skip_file_re='^_', out=False, files_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b88bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<documents title=\"GitHub repository contents from AnswerDotAI/toolslm/main/samples\"><document index=\"1\"><src>\n",
      "sample_core.py\n",
      "</src><document-content>\n",
      "import inspect\n",
      "empty = inspect.Parameter.empty\n",
      "models = 'claude-3-opus-20240229','claude-3-sonnet-20240229','claude-3-haiku-20240307'\n",
      "</document-content></document><document index=\"2\"><src>\n",
      "sample_styles.css\n",
      "</src><document-content>\n",
      ".cell { margin-bottom: 1rem; }\n",
      ".cell > .sourceCode { margin-bottom: 0; }\n",
      ".cell-output > pre { margin-bottom: 0; }\n",
      "</document-content></document></documents>\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(repo2ctx('https://github.com/AnswerDotAI/toolslm/tree/main/samples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec4289",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ee5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
